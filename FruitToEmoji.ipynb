{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "FruitToEmoji.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/erikk-avans/Machine-Learning/blob/master/FruitToEmoji.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f92-4Hjy7kA8"
      },
      "source": [
        "<a href=\"https://www.arduino.cc/\"><img src=\"https://raw.githubusercontent.com/sandeepmistry/aimldevfest-workshop-2019/master/images/Arduino_logo_R_highquality.png\" width=200/></a>\n",
        "# Tiny ML on Arduino\n",
        "## Classify objects by color tutorial\n",
        "\n",
        " \n",
        "https://github.com/arduino/ArduinoTensorFlowLiteTutorials/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uvDA8AK7QOq-"
      },
      "source": [
        "## Setup Python Environment \n",
        "\n",
        "The next cell sets up the dependencies in required for the notebook, run it."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y2gs-PL4xDkZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "23fd7415-9a70-4c30-ad8a-9df7291d2d62"
      },
      "source": [
        "# Setup environment\n",
        "!apt-get -qq install xxd\n",
        "#!pip install pandas numpy matplotlib\n",
        "%tensorflow_version 2.x\n",
        "#!pip install tensorflow"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Selecting previously unselected package xxd.\n",
            "(Reading database ... 160975 files and directories currently installed.)\n",
            "Preparing to unpack .../xxd_2%3a8.0.1453-1ubuntu1.4_amd64.deb ...\n",
            "Unpacking xxd (2:8.0.1453-1ubuntu1.4) ...\n",
            "Setting up xxd (2:8.0.1453-1ubuntu1.4) ...\n",
            "Processing triggers for man-db (2.8.3-2ubuntu0.1) ...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9lwkeshJk7dg"
      },
      "source": [
        "# Upload Data\n",
        "\n",
        "1. Open the panel on the left side of Colab by clicking on the __>__\n",
        "1. Select the Files tab\n",
        "1. Drag `csv` files from your computer to the tab to upload them into colab."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kSxUeYPNQbOg"
      },
      "source": [
        "# Train Neural Network\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gxk414PU3oy3"
      },
      "source": [
        "## Parse and prepare the data\n",
        "\n",
        "The next cell parses the csv files and transforms them to a format that will be used to train the full connected neural network.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AGChd1FAk5_j",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 508
        },
        "outputId": "00095126-58f6-4098-f8fc-3e1ad08c06b0"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "import os\n",
        "import fileinput\n",
        "\n",
        "print(f\"TensorFlow version = {tf.__version__}\\n\")\n",
        "\n",
        "# Set a fixed random seed value, for reproducibility, this will allow us to get\n",
        "# the same random numbers each time the notebook is run\n",
        "SEED = 1337\n",
        "np.random.seed(SEED)\n",
        "tf.random.set_seed(SEED)\n",
        "\n",
        "CLASSES = [];\n",
        "\n",
        "for file in os.listdir(\"/content/\"):\n",
        "    if file.endswith(\".csv\"):\n",
        "        CLASSES.append(os.path.splitext(file)[0])\n",
        "\n",
        "CLASSES.sort()\n",
        "\n",
        "SAMPLES_WINDOW_LEN = 1\n",
        "NUM_CLASSES = len(CLASSES)\n",
        "\n",
        "# create a one-hot encoded matrix that is used in the output\n",
        "ONE_HOT_ENCODED_CLASSES = np.eye(NUM_CLASSES)\n",
        "\n",
        "inputs = []\n",
        "outputs = []\n",
        "\n",
        "# read each csv file and push an input and output\n",
        "for class_index in range(NUM_CLASSES):\n",
        "  objectClass = CLASSES[class_index]\n",
        "  df = pd.read_csv(\"/content/\" + objectClass + \".csv\")\n",
        "  columns = list(df)\n",
        "  # get rid of pesky empty value lines of csv which cause NaN inputs to TensorFlow\n",
        "  df = df.dropna()\n",
        "  df = df.reset_index(drop=True)\n",
        "   \n",
        "  # calculate the number of objectClass recordings in the file\n",
        "  num_recordings = int(df.shape[0] / SAMPLES_WINDOW_LEN)\n",
        "  print(f\"\\u001b[32;4m{objectClass}\\u001b[0m class will be output \\u001b[32m{class_index}\\u001b[0m of the classifier\")\n",
        "  print(f\"{num_recordings} samples captured for training with inputs {list(df)} \\n\")\n",
        "\n",
        "  # graphing\n",
        "  plt.rcParams[\"figure.figsize\"] = (10,1)\n",
        "  pixels = np.array([df['Red'],df['Green'],df['Blue']],float)\n",
        "  pixels = np.transpose(pixels)\n",
        "  for i in range(num_recordings):\n",
        "    plt.axvline(x=i, linewidth=8, color=tuple(pixels[i]/np.max(pixels[i], axis=0)))\n",
        "  plt.show()\n",
        "  \n",
        "  #tensors\n",
        "  output = ONE_HOT_ENCODED_CLASSES[class_index]\n",
        "  for i in range(num_recordings):\n",
        "    tensor = []\n",
        "    row = []\n",
        "    for c in columns:\n",
        "      row.append(df[c][i])\n",
        "    tensor += row\n",
        "    inputs.append(tensor)\n",
        "    outputs.append(output)\n",
        "\n",
        "# convert the list to numpy array\n",
        "inputs = np.array(inputs)\n",
        "outputs = np.array(outputs)\n",
        "\n",
        "print(\"Data set parsing and preparation complete.\")\n",
        "\n",
        "# Randomize the order of the inputs, so they can be evenly distributed for training, testing, and validation\n",
        "# https://stackoverflow.com/a/37710486/2020087\n",
        "num_inputs = len(inputs)\n",
        "randomize = np.arange(num_inputs)\n",
        "np.random.shuffle(randomize)\n",
        "\n",
        "# Swap the consecutive indexes (0, 1, 2, etc) with the randomized indexes\n",
        "inputs = inputs[randomize]\n",
        "outputs = outputs[randomize]\n",
        "\n",
        "# Split the recordings (group of samples) into three sets: training, testing and validation\n",
        "TRAIN_SPLIT = int(0.6 * num_inputs)\n",
        "TEST_SPLIT = int(0.2 * num_inputs + TRAIN_SPLIT)\n",
        "\n",
        "inputs_train, inputs_test, inputs_validate = np.split(inputs, [TRAIN_SPLIT, TEST_SPLIT])\n",
        "outputs_train, outputs_test, outputs_validate = np.split(outputs, [TRAIN_SPLIT, TEST_SPLIT])\n",
        "\n",
        "print(\"Data set randomization and splitting complete.\")\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TensorFlow version = 2.4.1\n",
            "\n",
            "\u001b[32;4mBanana\u001b[0m class will be output \u001b[32m0\u001b[0m of the classifier\n",
            "344 samples captured for training with inputs ['Red', 'Green', 'Blue'] \n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x72 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32;4mSalad\u001b[0m class will be output \u001b[32m1\u001b[0m of the classifier\n",
            "246 samples captured for training with inputs ['Red', 'Green', 'Blue'] \n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x72 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32;4mTomato\u001b[0m class will be output \u001b[32m2\u001b[0m of the classifier\n",
            "269 samples captured for training with inputs ['Red', 'Green', 'Blue'] \n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x72 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Data set parsing and preparation complete.\n",
            "Data set randomization and splitting complete.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v8qlSAX1b6Yv"
      },
      "source": [
        "## Build & Train the Model\n",
        "\n",
        "Build and train a [TensorFlow](https://www.tensorflow.org) model using the high-level [Keras](https://www.tensorflow.org/guide/keras) API."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kGNFa-lX24Qo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9100e877-e472-4680-f9cd-bd615c4ec7d4"
      },
      "source": [
        "# build the model and train it\n",
        "model = tf.keras.Sequential()\n",
        "model.add(tf.keras.layers.Dense(8, activation='relu')) # relu is used for performance\n",
        "model.add(tf.keras.layers.Dense(5, activation='relu'))\n",
        "model.add(tf.keras.layers.Dense(NUM_CLASSES, activation='softmax')) # softmax is used, because we only expect one class to occur per input\n",
        "model.compile(optimizer='rmsprop', loss='mse', metrics=['mae'])\n",
        "history = model.fit(inputs_train, outputs_train, epochs=400, batch_size=4, validation_data=(inputs_validate, outputs_validate))\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/400\n",
            "129/129 [==============================] - 1s 4ms/step - loss: 0.2205 - mae: 0.4423 - val_loss: 0.2139 - val_mae: 0.4359\n",
            "Epoch 2/400\n",
            "129/129 [==============================] - 0s 1ms/step - loss: 0.2133 - mae: 0.4353 - val_loss: 0.2063 - val_mae: 0.4279\n",
            "Epoch 3/400\n",
            "129/129 [==============================] - 0s 1ms/step - loss: 0.2050 - mae: 0.4264 - val_loss: 0.1941 - val_mae: 0.4142\n",
            "Epoch 4/400\n",
            "129/129 [==============================] - 0s 1ms/step - loss: 0.1912 - mae: 0.4108 - val_loss: 0.1801 - val_mae: 0.3979\n",
            "Epoch 5/400\n",
            "129/129 [==============================] - 0s 1ms/step - loss: 0.1776 - mae: 0.3941 - val_loss: 0.1605 - val_mae: 0.3721\n",
            "Epoch 6/400\n",
            "129/129 [==============================] - 0s 1ms/step - loss: 0.1579 - mae: 0.3677 - val_loss: 0.1417 - val_mae: 0.3445\n",
            "Epoch 7/400\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.1407 - mae: 0.3414 - val_loss: 0.1245 - val_mae: 0.3159\n",
            "Epoch 8/400\n",
            "129/129 [==============================] - 0s 1ms/step - loss: 0.1240 - mae: 0.3137 - val_loss: 0.1080 - val_mae: 0.2874\n",
            "Epoch 9/400\n",
            "129/129 [==============================] - 0s 1ms/step - loss: 0.1070 - mae: 0.2847 - val_loss: 0.0940 - val_mae: 0.2631\n",
            "Epoch 10/400\n",
            "129/129 [==============================] - 0s 1ms/step - loss: 0.0945 - mae: 0.2638 - val_loss: 0.0793 - val_mae: 0.2360\n",
            "Epoch 11/400\n",
            "129/129 [==============================] - 0s 1ms/step - loss: 0.0814 - mae: 0.2402 - val_loss: 0.0694 - val_mae: 0.2169\n",
            "Epoch 12/400\n",
            "129/129 [==============================] - 0s 1ms/step - loss: 0.0647 - mae: 0.2095 - val_loss: 0.0570 - val_mae: 0.1922\n",
            "Epoch 13/400\n",
            "129/129 [==============================] - 0s 1ms/step - loss: 0.0553 - mae: 0.1917 - val_loss: 0.0479 - val_mae: 0.1737\n",
            "Epoch 14/400\n",
            "129/129 [==============================] - 0s 1ms/step - loss: 0.0460 - mae: 0.1720 - val_loss: 0.0386 - val_mae: 0.1535\n",
            "Epoch 15/400\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0357 - mae: 0.1479 - val_loss: 0.0331 - val_mae: 0.1383\n",
            "Epoch 16/400\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0310 - mae: 0.1358 - val_loss: 0.0261 - val_mae: 0.1206\n",
            "Epoch 17/400\n",
            "129/129 [==============================] - 0s 1ms/step - loss: 0.0221 - mae: 0.1121 - val_loss: 0.0214 - val_mae: 0.1063\n",
            "Epoch 18/400\n",
            "129/129 [==============================] - 0s 1ms/step - loss: 0.0201 - mae: 0.1021 - val_loss: 0.0175 - val_mae: 0.0930\n",
            "Epoch 19/400\n",
            "129/129 [==============================] - 0s 1ms/step - loss: 0.0142 - mae: 0.0854 - val_loss: 0.0160 - val_mae: 0.0839\n",
            "Epoch 20/400\n",
            "129/129 [==============================] - 0s 1ms/step - loss: 0.0134 - mae: 0.0794 - val_loss: 0.0116 - val_mae: 0.0714\n",
            "Epoch 21/400\n",
            "129/129 [==============================] - 0s 1ms/step - loss: 0.0093 - mae: 0.0673 - val_loss: 0.0102 - val_mae: 0.0631\n",
            "Epoch 22/400\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0074 - mae: 0.0587 - val_loss: 0.0088 - val_mae: 0.0564\n",
            "Epoch 23/400\n",
            "129/129 [==============================] - 0s 1ms/step - loss: 0.0067 - mae: 0.0542 - val_loss: 0.0081 - val_mae: 0.0511\n",
            "Epoch 24/400\n",
            "129/129 [==============================] - 0s 1ms/step - loss: 0.0052 - mae: 0.0460 - val_loss: 0.0069 - val_mae: 0.0477\n",
            "Epoch 25/400\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0060 - mae: 0.0479 - val_loss: 0.0075 - val_mae: 0.0429\n",
            "Epoch 26/400\n",
            "129/129 [==============================] - 0s 1ms/step - loss: 0.0043 - mae: 0.0390 - val_loss: 0.0059 - val_mae: 0.0382\n",
            "Epoch 27/400\n",
            "129/129 [==============================] - 0s 1ms/step - loss: 0.0047 - mae: 0.0386 - val_loss: 0.0058 - val_mae: 0.0354\n",
            "Epoch 28/400\n",
            "129/129 [==============================] - 0s 1ms/step - loss: 0.0030 - mae: 0.0326 - val_loss: 0.0051 - val_mae: 0.0325\n",
            "Epoch 29/400\n",
            "129/129 [==============================] - 0s 1ms/step - loss: 0.0039 - mae: 0.0325 - val_loss: 0.0061 - val_mae: 0.0313\n",
            "Epoch 30/400\n",
            "129/129 [==============================] - 0s 1ms/step - loss: 0.0039 - mae: 0.0311 - val_loss: 0.0052 - val_mae: 0.0285\n",
            "Epoch 31/400\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0036 - mae: 0.0278 - val_loss: 0.0052 - val_mae: 0.0269\n",
            "Epoch 32/400\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0035 - mae: 0.0269 - val_loss: 0.0044 - val_mae: 0.0245\n",
            "Epoch 33/400\n",
            "129/129 [==============================] - 0s 1ms/step - loss: 0.0017 - mae: 0.0202 - val_loss: 0.0034 - val_mae: 0.0219\n",
            "Epoch 34/400\n",
            "129/129 [==============================] - 0s 1ms/step - loss: 0.0020 - mae: 0.0195 - val_loss: 0.0036 - val_mae: 0.0206\n",
            "Epoch 35/400\n",
            "129/129 [==============================] - 0s 1ms/step - loss: 0.0020 - mae: 0.0201 - val_loss: 0.0040 - val_mae: 0.0196\n",
            "Epoch 36/400\n",
            "129/129 [==============================] - 0s 1ms/step - loss: 0.0027 - mae: 0.0206 - val_loss: 0.0042 - val_mae: 0.0188\n",
            "Epoch 37/400\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0017 - mae: 0.0162 - val_loss: 0.0035 - val_mae: 0.0172\n",
            "Epoch 38/400\n",
            "129/129 [==============================] - 0s 1ms/step - loss: 0.0012 - mae: 0.0140 - val_loss: 0.0022 - val_mae: 0.0166\n",
            "Epoch 39/400\n",
            "129/129 [==============================] - 0s 1ms/step - loss: 0.0011 - mae: 0.0144 - val_loss: 0.0030 - val_mae: 0.0154\n",
            "Epoch 40/400\n",
            "129/129 [==============================] - 0s 1ms/step - loss: 0.0015 - mae: 0.0140 - val_loss: 0.0024 - val_mae: 0.0147\n",
            "Epoch 41/400\n",
            "129/129 [==============================] - 0s 1ms/step - loss: 0.0015 - mae: 0.0139 - val_loss: 0.0022 - val_mae: 0.0143\n",
            "Epoch 42/400\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0015 - mae: 0.0146 - val_loss: 0.0025 - val_mae: 0.0135\n",
            "Epoch 43/400\n",
            "129/129 [==============================] - 0s 1ms/step - loss: 0.0014 - mae: 0.0138 - val_loss: 0.0026 - val_mae: 0.0130\n",
            "Epoch 44/400\n",
            "129/129 [==============================] - 0s 1ms/step - loss: 0.0012 - mae: 0.0122 - val_loss: 0.0019 - val_mae: 0.0128\n",
            "Epoch 45/400\n",
            "129/129 [==============================] - 0s 1ms/step - loss: 0.0011 - mae: 0.0125 - val_loss: 0.0016 - val_mae: 0.0131\n",
            "Epoch 46/400\n",
            "129/129 [==============================] - 0s 1ms/step - loss: 0.0011 - mae: 0.0126 - val_loss: 0.0017 - val_mae: 0.0121\n",
            "Epoch 47/400\n",
            "129/129 [==============================] - 0s 1ms/step - loss: 8.8326e-04 - mae: 0.0105 - val_loss: 0.0018 - val_mae: 0.0115\n",
            "Epoch 48/400\n",
            "129/129 [==============================] - 0s 1ms/step - loss: 7.5796e-04 - mae: 0.0098 - val_loss: 0.0013 - val_mae: 0.0139\n",
            "Epoch 49/400\n",
            "129/129 [==============================] - 0s 1ms/step - loss: 7.7582e-04 - mae: 0.0110 - val_loss: 0.0025 - val_mae: 0.0108\n",
            "Epoch 50/400\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0010 - mae: 0.0108 - val_loss: 0.0025 - val_mae: 0.0105\n",
            "Epoch 51/400\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 4.5733e-04 - mae: 0.0074 - val_loss: 0.0020 - val_mae: 0.0100\n",
            "Epoch 52/400\n",
            "129/129 [==============================] - 0s 1ms/step - loss: 0.0012 - mae: 0.0105 - val_loss: 0.0016 - val_mae: 0.0098\n",
            "Epoch 53/400\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 7.8345e-04 - mae: 0.0092 - val_loss: 0.0026 - val_mae: 0.0097\n",
            "Epoch 54/400\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 5.8354e-04 - mae: 0.0075 - val_loss: 0.0019 - val_mae: 0.0092\n",
            "Epoch 55/400\n",
            "129/129 [==============================] - 0s 1ms/step - loss: 8.5190e-04 - mae: 0.0090 - val_loss: 0.0020 - val_mae: 0.0090\n",
            "Epoch 56/400\n",
            "129/129 [==============================] - 0s 1ms/step - loss: 8.1548e-04 - mae: 0.0070 - val_loss: 0.0010 - val_mae: 0.0095\n",
            "Epoch 57/400\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 7.1056e-04 - mae: 0.0084 - val_loss: 0.0021 - val_mae: 0.0086\n",
            "Epoch 58/400\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 6.1848e-04 - mae: 0.0074 - val_loss: 0.0010 - val_mae: 0.0087\n",
            "Epoch 59/400\n",
            "129/129 [==============================] - 0s 1ms/step - loss: 5.8405e-04 - mae: 0.0089 - val_loss: 0.0038 - val_mae: 0.0097\n",
            "Epoch 60/400\n",
            "129/129 [==============================] - 0s 1ms/step - loss: 4.2827e-04 - mae: 0.0050 - val_loss: 0.0027 - val_mae: 0.0084\n",
            "Epoch 61/400\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 6.1806e-04 - mae: 0.0070 - val_loss: 9.7442e-04 - val_mae: 0.0078\n",
            "Epoch 62/400\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 3.7192e-04 - mae: 0.0065 - val_loss: 0.0026 - val_mae: 0.0081\n",
            "Epoch 63/400\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 0.0013 - mae: 0.0073 - val_loss: 0.0017 - val_mae: 0.0073\n",
            "Epoch 64/400\n",
            "129/129 [==============================] - 0s 1ms/step - loss: 5.5686e-04 - mae: 0.0066 - val_loss: 0.0014 - val_mae: 0.0070\n",
            "Epoch 65/400\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 4.0777e-04 - mae: 0.0044 - val_loss: 0.0019 - val_mae: 0.0071\n",
            "Epoch 66/400\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 8.4527e-04 - mae: 0.0071 - val_loss: 0.0021 - val_mae: 0.0072\n",
            "Epoch 67/400\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 6.0225e-04 - mae: 0.0059 - val_loss: 9.1813e-04 - val_mae: 0.0066\n",
            "Epoch 68/400\n",
            "129/129 [==============================] - 0s 1ms/step - loss: 3.4901e-04 - mae: 0.0057 - val_loss: 7.1710e-04 - val_mae: 0.0067\n",
            "Epoch 69/400\n",
            "129/129 [==============================] - 0s 1ms/step - loss: 2.0758e-04 - mae: 0.0046 - val_loss: 0.0010 - val_mae: 0.0062\n",
            "Epoch 70/400\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 2.2493e-04 - mae: 0.0035 - val_loss: 8.3173e-04 - val_mae: 0.0062\n",
            "Epoch 71/400\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 2.8148e-04 - mae: 0.0051 - val_loss: 9.3652e-04 - val_mae: 0.0060\n",
            "Epoch 72/400\n",
            "129/129 [==============================] - 0s 1ms/step - loss: 3.3128e-04 - mae: 0.0057 - val_loss: 0.0020 - val_mae: 0.0065\n",
            "Epoch 73/400\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 2.7320e-04 - mae: 0.0039 - val_loss: 7.3826e-04 - val_mae: 0.0057\n",
            "Epoch 74/400\n",
            "129/129 [==============================] - 0s 1ms/step - loss: 2.5478e-04 - mae: 0.0050 - val_loss: 8.0972e-04 - val_mae: 0.0056\n",
            "Epoch 75/400\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 3.7276e-04 - mae: 0.0061 - val_loss: 0.0013 - val_mae: 0.0056\n",
            "Epoch 76/400\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 1.9675e-04 - mae: 0.0036 - val_loss: 5.6071e-04 - val_mae: 0.0055\n",
            "Epoch 77/400\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 2.0982e-04 - mae: 0.0043 - val_loss: 0.0015 - val_mae: 0.0056\n",
            "Epoch 78/400\n",
            "129/129 [==============================] - 0s 1ms/step - loss: 2.6432e-04 - mae: 0.0039 - val_loss: 9.8253e-04 - val_mae: 0.0051\n",
            "Epoch 79/400\n",
            "129/129 [==============================] - 0s 1ms/step - loss: 1.3137e-04 - mae: 0.0033 - val_loss: 0.0013 - val_mae: 0.0053\n",
            "Epoch 80/400\n",
            "129/129 [==============================] - 0s 1ms/step - loss: 1.4970e-04 - mae: 0.0026 - val_loss: 7.0927e-04 - val_mae: 0.0048\n",
            "Epoch 81/400\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 2.3843e-04 - mae: 0.0043 - val_loss: 0.0015 - val_mae: 0.0054\n",
            "Epoch 82/400\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 2.6375e-04 - mae: 0.0031 - val_loss: 6.2565e-04 - val_mae: 0.0046\n",
            "Epoch 83/400\n",
            "129/129 [==============================] - 0s 1ms/step - loss: 2.4690e-04 - mae: 0.0040 - val_loss: 5.4313e-04 - val_mae: 0.0045\n",
            "Epoch 84/400\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 1.6627e-04 - mae: 0.0032 - val_loss: 6.9512e-04 - val_mae: 0.0045\n",
            "Epoch 85/400\n",
            "129/129 [==============================] - 0s 1ms/step - loss: 2.1075e-04 - mae: 0.0035 - val_loss: 8.4258e-04 - val_mae: 0.0045\n",
            "Epoch 86/400\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 1.2957e-04 - mae: 0.0026 - val_loss: 5.9053e-04 - val_mae: 0.0043\n",
            "Epoch 87/400\n",
            "129/129 [==============================] - 0s 1ms/step - loss: 1.0770e-04 - mae: 0.0031 - val_loss: 0.0014 - val_mae: 0.0049\n",
            "Epoch 88/400\n",
            "129/129 [==============================] - 0s 1ms/step - loss: 3.5445e-04 - mae: 0.0041 - val_loss: 0.0014 - val_mae: 0.0048\n",
            "Epoch 89/400\n",
            "129/129 [==============================] - 0s 1ms/step - loss: 1.6842e-04 - mae: 0.0032 - val_loss: 4.9977e-04 - val_mae: 0.0040\n",
            "Epoch 90/400\n",
            "129/129 [==============================] - 0s 1ms/step - loss: 1.2261e-04 - mae: 0.0030 - val_loss: 3.7230e-04 - val_mae: 0.0040\n",
            "Epoch 91/400\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 1.1641e-04 - mae: 0.0032 - val_loss: 5.0675e-04 - val_mae: 0.0039\n",
            "Epoch 92/400\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 1.7568e-04 - mae: 0.0040 - val_loss: 0.0027 - val_mae: 0.0061\n",
            "Epoch 93/400\n",
            "129/129 [==============================] - 0s 1ms/step - loss: 1.7982e-04 - mae: 0.0020 - val_loss: 0.0015 - val_mae: 0.0047\n",
            "Epoch 94/400\n",
            "129/129 [==============================] - 0s 1ms/step - loss: 2.1173e-04 - mae: 0.0024 - val_loss: 4.9719e-04 - val_mae: 0.0036\n",
            "Epoch 95/400\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 1.0383e-04 - mae: 0.0025 - val_loss: 4.2976e-04 - val_mae: 0.0035\n",
            "Epoch 96/400\n",
            "129/129 [==============================] - 0s 1ms/step - loss: 1.2142e-04 - mae: 0.0026 - val_loss: 3.8536e-04 - val_mae: 0.0034\n",
            "Epoch 97/400\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 1.3177e-04 - mae: 0.0030 - val_loss: 3.1954e-04 - val_mae: 0.0034\n",
            "Epoch 98/400\n",
            "129/129 [==============================] - 0s 1ms/step - loss: 5.4130e-05 - mae: 0.0022 - val_loss: 5.7380e-04 - val_mae: 0.0034\n",
            "Epoch 99/400\n",
            "129/129 [==============================] - 0s 1ms/step - loss: 1.6961e-04 - mae: 0.0032 - val_loss: 9.8824e-04 - val_mae: 0.0038\n",
            "Epoch 100/400\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 1.3225e-04 - mae: 0.0018 - val_loss: 2.8245e-04 - val_mae: 0.0031\n",
            "Epoch 101/400\n",
            "129/129 [==============================] - 0s 1ms/step - loss: 5.3960e-05 - mae: 0.0019 - val_loss: 5.8014e-04 - val_mae: 0.0033\n",
            "Epoch 102/400\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 9.6499e-05 - mae: 0.0022 - val_loss: 6.7775e-04 - val_mae: 0.0033\n",
            "Epoch 103/400\n",
            "129/129 [==============================] - 0s 1ms/step - loss: 1.3393e-04 - mae: 0.0022 - val_loss: 2.1137e-04 - val_mae: 0.0030\n",
            "Epoch 104/400\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 1.0830e-04 - mae: 0.0024 - val_loss: 2.8795e-04 - val_mae: 0.0029\n",
            "Epoch 105/400\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 1.0986e-04 - mae: 0.0024 - val_loss: 5.7915e-04 - val_mae: 0.0031\n",
            "Epoch 106/400\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 6.4502e-05 - mae: 0.0019 - val_loss: 2.4715e-04 - val_mae: 0.0028\n",
            "Epoch 107/400\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 5.9669e-05 - mae: 0.0018 - val_loss: 8.3307e-04 - val_mae: 0.0034\n",
            "Epoch 108/400\n",
            "129/129 [==============================] - 0s 1ms/step - loss: 9.2295e-05 - mae: 0.0018 - val_loss: 4.7931e-04 - val_mae: 0.0029\n",
            "Epoch 109/400\n",
            "129/129 [==============================] - 0s 1ms/step - loss: 1.0318e-04 - mae: 0.0024 - val_loss: 5.3034e-04 - val_mae: 0.0029\n",
            "Epoch 110/400\n",
            "129/129 [==============================] - 0s 1ms/step - loss: 8.2593e-05 - mae: 0.0026 - val_loss: 0.0015 - val_mae: 0.0042\n",
            "Epoch 111/400\n",
            "129/129 [==============================] - 0s 1ms/step - loss: 1.0937e-04 - mae: 0.0017 - val_loss: 6.2103e-04 - val_mae: 0.0030\n",
            "Epoch 112/400\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 5.8020e-05 - mae: 0.0018 - val_loss: 3.3728e-04 - val_mae: 0.0025\n",
            "Epoch 113/400\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 4.9233e-05 - mae: 0.0015 - val_loss: 3.4745e-04 - val_mae: 0.0025\n",
            "Epoch 114/400\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 2.3077e-05 - mae: 0.0011 - val_loss: 1.3921e-04 - val_mae: 0.0024\n",
            "Epoch 115/400\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 3.5229e-05 - mae: 0.0015 - val_loss: 3.5196e-04 - val_mae: 0.0024\n",
            "Epoch 116/400\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 4.6744e-05 - mae: 0.0016 - val_loss: 6.4683e-04 - val_mae: 0.0029\n",
            "Epoch 117/400\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 5.2524e-05 - mae: 0.0015 - val_loss: 3.0713e-04 - val_mae: 0.0023\n",
            "Epoch 118/400\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 3.5378e-05 - mae: 0.0014 - val_loss: 2.0766e-04 - val_mae: 0.0022\n",
            "Epoch 119/400\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 2.7078e-05 - mae: 0.0011 - val_loss: 1.7489e-04 - val_mae: 0.0021\n",
            "Epoch 120/400\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 1.8171e-05 - mae: 0.0012 - val_loss: 1.4047e-04 - val_mae: 0.0021\n",
            "Epoch 121/400\n",
            "129/129 [==============================] - 0s 1ms/step - loss: 3.5604e-05 - mae: 0.0015 - val_loss: 3.0730e-04 - val_mae: 0.0022\n",
            "Epoch 122/400\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 4.5443e-05 - mae: 0.0013 - val_loss: 1.0309e-04 - val_mae: 0.0020\n",
            "Epoch 123/400\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 8.0533e-05 - mae: 9.0005e-04 - val_loss: 7.8335e-04 - val_mae: 0.0029\n",
            "Epoch 124/400\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 2.5557e-05 - mae: 9.3801e-04 - val_loss: 2.7453e-04 - val_mae: 0.0021\n",
            "Epoch 125/400\n",
            "129/129 [==============================] - 0s 1ms/step - loss: 2.0386e-05 - mae: 0.0011 - val_loss: 3.1268e-04 - val_mae: 0.0021\n",
            "Epoch 126/400\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 3.5441e-05 - mae: 0.0013 - val_loss: 2.2548e-04 - val_mae: 0.0019\n",
            "Epoch 127/400\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 2.4662e-05 - mae: 0.0011 - val_loss: 8.5386e-04 - val_mae: 0.0030\n",
            "Epoch 128/400\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 9.7971e-05 - mae: 0.0010 - val_loss: 3.2079e-04 - val_mae: 0.0020\n",
            "Epoch 129/400\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 2.7002e-05 - mae: 8.4062e-04 - val_loss: 0.0011 - val_mae: 0.0033\n",
            "Epoch 130/400\n",
            "129/129 [==============================] - 0s 1ms/step - loss: 5.7455e-05 - mae: 0.0013 - val_loss: 0.0013 - val_mae: 0.0036\n",
            "Epoch 131/400\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 9.1923e-05 - mae: 9.1850e-04 - val_loss: 2.5236e-04 - val_mae: 0.0019\n",
            "Epoch 132/400\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 2.8996e-05 - mae: 0.0011 - val_loss: 7.2372e-04 - val_mae: 0.0027\n",
            "Epoch 133/400\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 7.0106e-05 - mae: 7.6967e-04 - val_loss: 2.9298e-04 - val_mae: 0.0019\n",
            "Epoch 134/400\n",
            "129/129 [==============================] - 0s 1ms/step - loss: 1.8715e-05 - mae: 5.3395e-04 - val_loss: 2.0030e-04 - val_mae: 0.0017\n",
            "Epoch 135/400\n",
            "129/129 [==============================] - 0s 1ms/step - loss: 1.5331e-05 - mae: 9.5072e-04 - val_loss: 9.3717e-04 - val_mae: 0.0030\n",
            "Epoch 136/400\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 8.3319e-05 - mae: 6.6738e-04 - val_loss: 2.1156e-04 - val_mae: 0.0017\n",
            "Epoch 137/400\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 1.4737e-05 - mae: 8.9582e-04 - val_loss: 2.5982e-04 - val_mae: 0.0018\n",
            "Epoch 138/400\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 3.9735e-05 - mae: 7.4875e-04 - val_loss: 8.3587e-05 - val_mae: 0.0015\n",
            "Epoch 139/400\n",
            "129/129 [==============================] - 0s 1ms/step - loss: 1.7314e-05 - mae: 8.1707e-04 - val_loss: 2.9179e-04 - val_mae: 0.0018\n",
            "Epoch 140/400\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 1.7795e-05 - mae: 7.9494e-04 - val_loss: 9.6055e-05 - val_mae: 0.0014\n",
            "Epoch 141/400\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 1.0897e-05 - mae: 9.9462e-04 - val_loss: 4.7358e-04 - val_mae: 0.0021\n",
            "Epoch 142/400\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 6.5551e-05 - mae: 0.0015 - val_loss: 3.7503e-04 - val_mae: 0.0019\n",
            "Epoch 143/400\n",
            "129/129 [==============================] - 0s 1ms/step - loss: 1.6395e-05 - mae: 7.9776e-04 - val_loss: 1.7533e-04 - val_mae: 0.0015\n",
            "Epoch 144/400\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 1.6707e-05 - mae: 7.5102e-04 - val_loss: 2.8895e-04 - val_mae: 0.0017\n",
            "Epoch 145/400\n",
            "129/129 [==============================] - 0s 1ms/step - loss: 3.3124e-05 - mae: 5.5971e-04 - val_loss: 5.3095e-05 - val_mae: 0.0013\n",
            "Epoch 146/400\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 1.1949e-05 - mae: 9.3599e-04 - val_loss: 1.1253e-04 - val_mae: 0.0013\n",
            "Epoch 147/400\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 1.1115e-05 - mae: 8.4286e-04 - val_loss: 4.2195e-04 - val_mae: 0.0020\n",
            "Epoch 148/400\n",
            "129/129 [==============================] - 0s 1ms/step - loss: 5.9368e-05 - mae: 6.6578e-04 - val_loss: 1.1152e-04 - val_mae: 0.0013\n",
            "Epoch 149/400\n",
            "129/129 [==============================] - 0s 1ms/step - loss: 1.9730e-05 - mae: 8.9657e-04 - val_loss: 3.3422e-04 - val_mae: 0.0018\n",
            "Epoch 150/400\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 1.7702e-05 - mae: 7.3041e-04 - val_loss: 1.1938e-04 - val_mae: 0.0013\n",
            "Epoch 151/400\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 1.0246e-05 - mae: 5.3398e-04 - val_loss: 1.1495e-04 - val_mae: 0.0013\n",
            "Epoch 152/400\n",
            "129/129 [==============================] - 0s 1ms/step - loss: 1.6606e-05 - mae: 6.3444e-04 - val_loss: 9.0264e-05 - val_mae: 0.0012\n",
            "Epoch 153/400\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 5.4585e-06 - mae: 5.6957e-04 - val_loss: 5.7894e-04 - val_mae: 0.0022\n",
            "Epoch 154/400\n",
            "129/129 [==============================] - 0s 1ms/step - loss: 1.7138e-05 - mae: 6.6189e-04 - val_loss: 2.9243e-04 - val_mae: 0.0016\n",
            "Epoch 155/400\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 7.6658e-06 - mae: 5.3577e-04 - val_loss: 6.5075e-05 - val_mae: 0.0011\n",
            "Epoch 156/400\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 1.3981e-05 - mae: 6.5871e-04 - val_loss: 9.3389e-05 - val_mae: 0.0011\n",
            "Epoch 157/400\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 1.0667e-05 - mae: 6.1320e-04 - val_loss: 1.2796e-04 - val_mae: 0.0012\n",
            "Epoch 158/400\n",
            "129/129 [==============================] - 0s 1ms/step - loss: 6.6820e-06 - mae: 5.2494e-04 - val_loss: 9.2415e-05 - val_mae: 0.0011\n",
            "Epoch 159/400\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 7.3188e-06 - mae: 6.7192e-04 - val_loss: 4.4594e-04 - val_mae: 0.0019\n",
            "Epoch 160/400\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 1.6575e-05 - mae: 6.5952e-04 - val_loss: 1.3149e-04 - val_mae: 0.0012\n",
            "Epoch 161/400\n",
            "129/129 [==============================] - 0s 1ms/step - loss: 7.6764e-06 - mae: 5.0815e-04 - val_loss: 7.7558e-05 - val_mae: 0.0010\n",
            "Epoch 162/400\n",
            "129/129 [==============================] - 0s 1ms/step - loss: 9.2566e-06 - mae: 3.9626e-04 - val_loss: 1.2057e-04 - val_mae: 0.0011\n",
            "Epoch 163/400\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 6.7695e-06 - mae: 4.4579e-04 - val_loss: 1.9273e-04 - val_mae: 0.0013\n",
            "Epoch 164/400\n",
            "129/129 [==============================] - 0s 1ms/step - loss: 2.1597e-05 - mae: 5.6876e-04 - val_loss: 1.3304e-04 - val_mae: 0.0011\n",
            "Epoch 165/400\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 7.5475e-06 - mae: 4.3618e-04 - val_loss: 9.0381e-05 - val_mae: 0.0010\n",
            "Epoch 166/400\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 5.4015e-06 - mae: 5.8387e-04 - val_loss: 7.6514e-05 - val_mae: 9.6339e-04\n",
            "Epoch 167/400\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 4.2111e-06 - mae: 4.8307e-04 - val_loss: 1.0085e-04 - val_mae: 0.0010\n",
            "Epoch 168/400\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 4.7495e-06 - mae: 3.8406e-04 - val_loss: 1.9249e-05 - val_mae: 8.5391e-04\n",
            "Epoch 169/400\n",
            "129/129 [==============================] - 0s 1ms/step - loss: 6.1346e-06 - mae: 6.2989e-04 - val_loss: 9.6877e-05 - val_mae: 9.8956e-04\n",
            "Epoch 170/400\n",
            "129/129 [==============================] - 0s 1ms/step - loss: 1.0035e-05 - mae: 6.1639e-04 - val_loss: 1.9739e-04 - val_mae: 0.0013\n",
            "Epoch 171/400\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 1.3201e-05 - mae: 6.3480e-04 - val_loss: 4.2052e-05 - val_mae: 7.9418e-04\n",
            "Epoch 172/400\n",
            "129/129 [==============================] - 0s 1ms/step - loss: 7.1071e-06 - mae: 5.2075e-04 - val_loss: 4.4528e-05 - val_mae: 7.8890e-04\n",
            "Epoch 173/400\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 3.2311e-06 - mae: 3.8218e-04 - val_loss: 1.7398e-05 - val_mae: 7.5089e-04\n",
            "Epoch 174/400\n",
            "129/129 [==============================] - 0s 1ms/step - loss: 4.2855e-06 - mae: 5.1176e-04 - val_loss: 7.8067e-05 - val_mae: 8.8075e-04\n",
            "Epoch 175/400\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 1.9675e-06 - mae: 2.9210e-04 - val_loss: 4.3190e-05 - val_mae: 7.5232e-04\n",
            "Epoch 176/400\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 5.1898e-06 - mae: 5.4805e-04 - val_loss: 2.0413e-04 - val_mae: 0.0012\n",
            "Epoch 177/400\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 2.3809e-05 - mae: 3.5124e-04 - val_loss: 3.6452e-05 - val_mae: 7.1248e-04\n",
            "Epoch 178/400\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 2.3805e-06 - mae: 3.5850e-04 - val_loss: 1.9199e-04 - val_mae: 0.0012\n",
            "Epoch 179/400\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 7.2658e-06 - mae: 3.7145e-04 - val_loss: 4.6536e-05 - val_mae: 7.2985e-04\n",
            "Epoch 180/400\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 1.3671e-06 - mae: 2.9333e-04 - val_loss: 2.6641e-05 - val_mae: 6.4965e-04\n",
            "Epoch 181/400\n",
            "129/129 [==============================] - 0s 1ms/step - loss: 2.0579e-06 - mae: 3.6608e-04 - val_loss: 6.7956e-05 - val_mae: 7.9353e-04\n",
            "Epoch 182/400\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 5.0361e-06 - mae: 4.9860e-04 - val_loss: 2.8249e-04 - val_mae: 0.0014\n",
            "Epoch 183/400\n",
            "129/129 [==============================] - 0s 1ms/step - loss: 2.7056e-06 - mae: 2.5788e-04 - val_loss: 6.6738e-05 - val_mae: 7.7481e-04\n",
            "Epoch 184/400\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 1.8096e-06 - mae: 3.1190e-04 - val_loss: 3.6061e-04 - val_mae: 0.0016\n",
            "Epoch 185/400\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 1.9784e-06 - mae: 2.5362e-04 - val_loss: 3.3278e-04 - val_mae: 0.0015\n",
            "Epoch 186/400\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 8.2049e-06 - mae: 3.0240e-04 - val_loss: 1.5174e-05 - val_mae: 5.6104e-04\n",
            "Epoch 187/400\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 1.5289e-06 - mae: 2.8950e-04 - val_loss: 6.2489e-05 - val_mae: 7.3236e-04\n",
            "Epoch 188/400\n",
            "129/129 [==============================] - 0s 1ms/step - loss: 2.7015e-06 - mae: 3.1006e-04 - val_loss: 4.3750e-05 - val_mae: 6.4723e-04\n",
            "Epoch 189/400\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 3.4192e-06 - mae: 2.4520e-04 - val_loss: 1.7496e-04 - val_mae: 0.0011\n",
            "Epoch 190/400\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 2.1629e-06 - mae: 2.4375e-04 - val_loss: 2.2492e-05 - val_mae: 5.4213e-04\n",
            "Epoch 191/400\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 2.6918e-06 - mae: 2.8116e-04 - val_loss: 4.0767e-05 - val_mae: 6.1860e-04\n",
            "Epoch 192/400\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 1.7500e-06 - mae: 2.5336e-04 - val_loss: 8.1640e-05 - val_mae: 7.8423e-04\n",
            "Epoch 193/400\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 3.5580e-06 - mae: 2.0946e-04 - val_loss: 5.9494e-05 - val_mae: 6.9196e-04\n",
            "Epoch 194/400\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 1.8527e-06 - mae: 2.8018e-04 - val_loss: 8.4759e-05 - val_mae: 7.8902e-04\n",
            "Epoch 195/400\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 1.2631e-06 - mae: 2.2823e-04 - val_loss: 1.5757e-05 - val_mae: 4.8125e-04\n",
            "Epoch 196/400\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 1.0132e-06 - mae: 2.2422e-04 - val_loss: 6.8672e-06 - val_mae: 4.6641e-04\n",
            "Epoch 197/400\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 1.1329e-06 - mae: 2.9551e-04 - val_loss: 3.9018e-05 - val_mae: 5.7914e-04\n",
            "Epoch 198/400\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 1.2164e-06 - mae: 1.7893e-04 - val_loss: 3.7158e-05 - val_mae: 5.6576e-04\n",
            "Epoch 199/400\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 3.3930e-06 - mae: 1.4560e-04 - val_loss: 5.2846e-05 - val_mae: 6.3813e-04\n",
            "Epoch 200/400\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 1.1012e-06 - mae: 2.3080e-04 - val_loss: 1.4052e-04 - val_mae: 9.6005e-04\n",
            "Epoch 201/400\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 1.5860e-06 - mae: 2.2868e-04 - val_loss: 4.6066e-05 - val_mae: 5.9880e-04\n",
            "Epoch 202/400\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 4.3430e-07 - mae: 1.2022e-04 - val_loss: 1.1034e-05 - val_mae: 4.1612e-04\n",
            "Epoch 203/400\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 8.9460e-07 - mae: 2.1289e-04 - val_loss: 1.3648e-04 - val_mae: 9.3789e-04\n",
            "Epoch 204/400\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 7.9910e-07 - mae: 1.4927e-04 - val_loss: 5.6277e-05 - val_mae: 6.3445e-04\n",
            "Epoch 205/400\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 1.6918e-06 - mae: 2.2332e-04 - val_loss: 1.3044e-05 - val_mae: 4.0389e-04\n",
            "Epoch 206/400\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 1.6224e-06 - mae: 2.7959e-04 - val_loss: 2.9460e-05 - val_mae: 4.9293e-04\n",
            "Epoch 207/400\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 8.5148e-07 - mae: 1.6420e-04 - val_loss: 1.8058e-05 - val_mae: 4.2364e-04\n",
            "Epoch 208/400\n",
            "129/129 [==============================] - 0s 1ms/step - loss: 4.5839e-07 - mae: 1.5889e-04 - val_loss: 4.1071e-05 - val_mae: 5.4862e-04\n",
            "Epoch 209/400\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 2.3797e-07 - mae: 1.2246e-04 - val_loss: 3.4969e-06 - val_mae: 3.7102e-04\n",
            "Epoch 210/400\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 7.5812e-07 - mae: 1.6419e-04 - val_loss: 3.7309e-05 - val_mae: 5.2340e-04\n",
            "Epoch 211/400\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 5.5103e-07 - mae: 1.2974e-04 - val_loss: 2.3977e-05 - val_mae: 4.4669e-04\n",
            "Epoch 212/400\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 5.7171e-07 - mae: 1.5690e-04 - val_loss: 3.7569e-05 - val_mae: 5.2019e-04\n",
            "Epoch 213/400\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 3.9150e-07 - mae: 1.4207e-04 - val_loss: 2.2758e-05 - val_mae: 4.3080e-04\n",
            "Epoch 214/400\n",
            "129/129 [==============================] - 0s 1ms/step - loss: 3.5046e-07 - mae: 1.1476e-04 - val_loss: 1.0007e-04 - val_mae: 7.8505e-04\n",
            "Epoch 215/400\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 1.4017e-06 - mae: 1.6612e-04 - val_loss: 2.2525e-05 - val_mae: 4.2271e-04\n",
            "Epoch 216/400\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 2.3638e-07 - mae: 1.1139e-04 - val_loss: 1.2629e-05 - val_mae: 3.5242e-04\n",
            "Epoch 217/400\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 9.4361e-07 - mae: 1.3893e-04 - val_loss: 4.5917e-05 - val_mae: 5.4952e-04\n",
            "Epoch 218/400\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 7.3065e-07 - mae: 1.4312e-04 - val_loss: 1.0985e-04 - val_mae: 8.1178e-04\n",
            "Epoch 219/400\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 6.8366e-07 - mae: 1.1752e-04 - val_loss: 1.8283e-05 - val_mae: 3.8401e-04\n",
            "Epoch 220/400\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 3.3303e-07 - mae: 9.8826e-05 - val_loss: 7.1217e-06 - val_mae: 3.0050e-04\n",
            "Epoch 221/400\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 2.1579e-07 - mae: 1.1287e-04 - val_loss: 7.7554e-06 - val_mae: 3.0081e-04\n",
            "Epoch 222/400\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 5.6214e-07 - mae: 1.2146e-04 - val_loss: 1.2048e-05 - val_mae: 3.2931e-04\n",
            "Epoch 223/400\n",
            "129/129 [==============================] - 0s 1ms/step - loss: 6.2006e-07 - mae: 1.5900e-04 - val_loss: 3.3469e-05 - val_mae: 4.6899e-04\n",
            "Epoch 224/400\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 1.9419e-06 - mae: 1.5370e-04 - val_loss: 3.2805e-05 - val_mae: 4.6377e-04\n",
            "Epoch 225/400\n",
            "129/129 [==============================] - 0s 1ms/step - loss: 4.5289e-07 - mae: 1.4486e-04 - val_loss: 1.5943e-05 - val_mae: 3.5065e-04\n",
            "Epoch 226/400\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 5.6077e-07 - mae: 1.2532e-04 - val_loss: 2.0459e-05 - val_mae: 3.8147e-04\n",
            "Epoch 227/400\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 2.6739e-07 - mae: 8.8683e-05 - val_loss: 1.4514e-05 - val_mae: 3.3592e-04\n",
            "Epoch 228/400\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 2.5011e-07 - mae: 1.1415e-04 - val_loss: 2.5553e-05 - val_mae: 4.1192e-04\n",
            "Epoch 229/400\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 6.0699e-07 - mae: 8.0978e-05 - val_loss: 1.4356e-05 - val_mae: 3.3210e-04\n",
            "Epoch 230/400\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 3.1430e-07 - mae: 1.2143e-04 - val_loss: 9.8443e-05 - val_mae: 7.4902e-04\n",
            "Epoch 231/400\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 3.5189e-06 - mae: 1.1947e-04 - val_loss: 1.0188e-05 - val_mae: 2.9376e-04\n",
            "Epoch 232/400\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 2.6438e-07 - mae: 1.0902e-04 - val_loss: 4.8605e-05 - val_mae: 5.3575e-04\n",
            "Epoch 233/400\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 1.7701e-06 - mae: 7.6816e-05 - val_loss: 3.3015e-05 - val_mae: 4.5063e-04\n",
            "Epoch 234/400\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 3.1071e-07 - mae: 1.0002e-04 - val_loss: 3.5936e-04 - val_mae: 0.0014\n",
            "Epoch 235/400\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 5.9921e-06 - mae: 1.2336e-04 - val_loss: 1.4929e-05 - val_mae: 3.2666e-04\n",
            "Epoch 236/400\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 2.4667e-07 - mae: 9.7519e-05 - val_loss: 3.8983e-06 - val_mae: 2.2876e-04\n",
            "Epoch 237/400\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 1.3473e-07 - mae: 7.4036e-05 - val_loss: 1.2366e-05 - val_mae: 3.0194e-04\n",
            "Epoch 238/400\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 3.7268e-07 - mae: 1.0362e-04 - val_loss: 1.0103e-04 - val_mae: 7.4977e-04\n",
            "Epoch 239/400\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 1.0672e-07 - mae: 4.3165e-05 - val_loss: 1.5521e-05 - val_mae: 3.2560e-04\n",
            "Epoch 240/400\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 2.3266e-07 - mae: 9.0626e-05 - val_loss: 7.4026e-05 - val_mae: 6.4239e-04\n",
            "Epoch 241/400\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 1.3130e-06 - mae: 1.0970e-04 - val_loss: 1.6913e-04 - val_mae: 9.6329e-04\n",
            "Epoch 242/400\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 2.6781e-07 - mae: 6.8902e-05 - val_loss: 2.6855e-06 - val_mae: 2.0474e-04\n",
            "Epoch 243/400\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 1.5217e-07 - mae: 8.2087e-05 - val_loss: 2.4503e-06 - val_mae: 1.9992e-04\n",
            "Epoch 244/400\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 1.9585e-07 - mae: 1.0464e-04 - val_loss: 1.3223e-05 - val_mae: 2.9863e-04\n",
            "Epoch 245/400\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 1.4227e-07 - mae: 7.6587e-05 - val_loss: 2.5716e-05 - val_mae: 3.9097e-04\n",
            "Epoch 246/400\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 5.3698e-07 - mae: 1.1882e-04 - val_loss: 1.4910e-05 - val_mae: 3.1068e-04\n",
            "Epoch 247/400\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 1.8294e-07 - mae: 7.7240e-05 - val_loss: 7.2099e-05 - val_mae: 6.2775e-04\n",
            "Epoch 248/400\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 1.2973e-06 - mae: 1.1544e-04 - val_loss: 5.3259e-06 - val_mae: 2.1738e-04\n",
            "Epoch 249/400\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 3.2110e-07 - mae: 1.0155e-04 - val_loss: 1.8816e-04 - val_mae: 0.0010\n",
            "Epoch 250/400\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 1.4769e-07 - mae: 5.7621e-05 - val_loss: 4.3648e-05 - val_mae: 4.9182e-04\n",
            "Epoch 251/400\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 1.2624e-07 - mae: 6.8440e-05 - val_loss: 1.6240e-05 - val_mae: 3.1602e-04\n",
            "Epoch 252/400\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 3.3991e-07 - mae: 1.0544e-04 - val_loss: 1.8550e-05 - val_mae: 3.3285e-04\n",
            "Epoch 253/400\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 4.4847e-07 - mae: 7.7430e-05 - val_loss: 2.0454e-05 - val_mae: 3.4654e-04\n",
            "Epoch 254/400\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 8.8327e-08 - mae: 5.7880e-05 - val_loss: 3.0111e-06 - val_mae: 1.8177e-04\n",
            "Epoch 255/400\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 1.0124e-07 - mae: 7.1122e-05 - val_loss: 1.8436e-05 - val_mae: 3.2956e-04\n",
            "Epoch 256/400\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 8.0630e-08 - mae: 4.9528e-05 - val_loss: 7.4023e-06 - val_mae: 2.2914e-04\n",
            "Epoch 257/400\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 1.5140e-07 - mae: 7.2955e-05 - val_loss: 7.3721e-05 - val_mae: 6.2566e-04\n",
            "Epoch 258/400\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 4.8550e-07 - mae: 5.6688e-05 - val_loss: 1.2414e-05 - val_mae: 2.7689e-04\n",
            "Epoch 259/400\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 5.6080e-07 - mae: 8.5911e-05 - val_loss: 1.1111e-05 - val_mae: 2.6398e-04\n",
            "Epoch 260/400\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 2.5690e-07 - mae: 5.4770e-05 - val_loss: 1.4816e-06 - val_mae: 1.5693e-04\n",
            "Epoch 261/400\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 2.2497e-07 - mae: 9.4632e-05 - val_loss: 2.0069e-05 - val_mae: 3.3752e-04\n",
            "Epoch 262/400\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 2.0567e-07 - mae: 8.7042e-05 - val_loss: 3.9009e-05 - val_mae: 4.5750e-04\n",
            "Epoch 263/400\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 5.7846e-08 - mae: 4.9348e-05 - val_loss: 1.9035e-06 - val_mae: 1.5297e-04\n",
            "Epoch 264/400\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 1.0901e-07 - mae: 7.1363e-05 - val_loss: 1.1300e-05 - val_mae: 2.6078e-04\n",
            "Epoch 265/400\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 7.0367e-08 - mae: 5.1104e-05 - val_loss: 5.3055e-06 - val_mae: 1.9496e-04\n",
            "Epoch 266/400\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 6.3300e-08 - mae: 6.1755e-05 - val_loss: 2.5617e-05 - val_mae: 3.7296e-04\n",
            "Epoch 267/400\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 1.4285e-07 - mae: 7.1365e-05 - val_loss: 3.5517e-05 - val_mae: 4.3404e-04\n",
            "Epoch 268/400\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 1.1168e-07 - mae: 5.8944e-05 - val_loss: 9.4817e-06 - val_mae: 2.3927e-04\n",
            "Epoch 269/400\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 6.9006e-08 - mae: 4.3143e-05 - val_loss: 3.4750e-06 - val_mae: 1.6587e-04\n",
            "Epoch 270/400\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 6.4950e-08 - mae: 5.7708e-05 - val_loss: 3.7274e-06 - val_mae: 1.6864e-04\n",
            "Epoch 271/400\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 3.7032e-08 - mae: 4.0189e-05 - val_loss: 7.2070e-05 - val_mae: 6.0982e-04\n",
            "Epoch 272/400\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 2.5683e-08 - mae: 2.9266e-05 - val_loss: 6.3897e-06 - val_mae: 2.0174e-04\n",
            "Epoch 273/400\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 1.4507e-07 - mae: 4.3793e-05 - val_loss: 6.6132e-06 - val_mae: 2.0396e-04\n",
            "Epoch 274/400\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 3.7840e-08 - mae: 4.6071e-05 - val_loss: 4.7793e-06 - val_mae: 1.7980e-04\n",
            "Epoch 275/400\n",
            "129/129 [==============================] - 0s 1ms/step - loss: 1.2169e-07 - mae: 6.3313e-05 - val_loss: 3.2914e-06 - val_mae: 1.5793e-04\n",
            "Epoch 276/400\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 1.1536e-07 - mae: 4.1330e-05 - val_loss: 7.2011e-06 - val_mae: 2.0918e-04\n",
            "Epoch 277/400\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 5.1758e-08 - mae: 5.0421e-05 - val_loss: 3.8572e-05 - val_mae: 4.4577e-04\n",
            "Epoch 278/400\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 2.1321e-07 - mae: 5.7045e-05 - val_loss: 5.3153e-05 - val_mae: 5.2068e-04\n",
            "Epoch 279/400\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 4.7663e-08 - mae: 3.8666e-05 - val_loss: 1.2919e-05 - val_mae: 2.6615e-04\n",
            "Epoch 280/400\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 9.5126e-08 - mae: 4.4142e-05 - val_loss: 5.8968e-06 - val_mae: 1.9053e-04\n",
            "Epoch 281/400\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 2.3113e-08 - mae: 3.5563e-05 - val_loss: 8.0756e-07 - val_mae: 1.1426e-04\n",
            "Epoch 282/400\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 7.1710e-08 - mae: 5.7440e-05 - val_loss: 3.9086e-06 - val_mae: 1.6193e-04\n",
            "Epoch 283/400\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 2.0800e-08 - mae: 3.3178e-05 - val_loss: 6.9476e-07 - val_mae: 1.1053e-04\n",
            "Epoch 284/400\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 8.6150e-08 - mae: 5.5068e-05 - val_loss: 5.6467e-06 - val_mae: 1.8511e-04\n",
            "Epoch 285/400\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 1.7332e-07 - mae: 4.5645e-05 - val_loss: 1.8023e-06 - val_mae: 1.2556e-04\n",
            "Epoch 286/400\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 3.9609e-08 - mae: 4.2702e-05 - val_loss: 8.4938e-07 - val_mae: 1.0837e-04\n",
            "Epoch 287/400\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 4.6103e-08 - mae: 4.7834e-05 - val_loss: 4.7799e-05 - val_mae: 4.9042e-04\n",
            "Epoch 288/400\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 2.6876e-07 - mae: 5.7374e-05 - val_loss: 2.4323e-05 - val_mae: 3.5309e-04\n",
            "Epoch 289/400\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 4.1360e-08 - mae: 3.0936e-05 - val_loss: 9.6304e-07 - val_mae: 1.0697e-04\n",
            "Epoch 290/400\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 3.2406e-08 - mae: 3.7801e-05 - val_loss: 2.3942e-06 - val_mae: 1.3226e-04\n",
            "Epoch 291/400\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 7.2350e-08 - mae: 5.0832e-05 - val_loss: 2.9885e-05 - val_mae: 3.8875e-04\n",
            "Epoch 292/400\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 1.8326e-07 - mae: 5.9082e-05 - val_loss: 2.5132e-05 - val_mae: 3.5726e-04\n",
            "Epoch 293/400\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 3.4399e-08 - mae: 3.4438e-05 - val_loss: 2.3594e-05 - val_mae: 3.4614e-04\n",
            "Epoch 294/400\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 1.2791e-08 - mae: 2.1998e-05 - val_loss: 6.1192e-06 - val_mae: 1.8613e-04\n",
            "Epoch 295/400\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 4.9869e-08 - mae: 3.3687e-05 - val_loss: 1.7073e-05 - val_mae: 2.9604e-04\n",
            "Epoch 296/400\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 6.3530e-08 - mae: 2.8034e-05 - val_loss: 1.6675e-06 - val_mae: 1.1479e-04\n",
            "Epoch 297/400\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 2.6954e-08 - mae: 3.8555e-05 - val_loss: 2.1793e-05 - val_mae: 3.3201e-04\n",
            "Epoch 298/400\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 5.6015e-08 - mae: 4.7103e-05 - val_loss: 4.0047e-06 - val_mae: 1.5478e-04\n",
            "Epoch 299/400\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 1.1815e-08 - mae: 2.3246e-05 - val_loss: 3.8750e-06 - val_mae: 1.5210e-04\n",
            "Epoch 300/400\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 1.5137e-08 - mae: 2.2707e-05 - val_loss: 6.9485e-06 - val_mae: 1.9440e-04\n",
            "Epoch 301/400\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 2.7591e-08 - mae: 3.2999e-05 - val_loss: 3.1465e-05 - val_mae: 3.9493e-04\n",
            "Epoch 302/400\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 2.0539e-08 - mae: 2.5018e-05 - val_loss: 3.4756e-05 - val_mae: 4.1408e-04\n",
            "Epoch 303/400\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 1.9666e-07 - mae: 4.4442e-05 - val_loss: 3.9211e-06 - val_mae: 1.5145e-04\n",
            "Epoch 304/400\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 2.1928e-08 - mae: 2.9958e-05 - val_loss: 2.3352e-05 - val_mae: 3.4062e-04\n",
            "Epoch 305/400\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 7.5682e-08 - mae: 2.3358e-05 - val_loss: 3.4750e-06 - val_mae: 1.4347e-04\n",
            "Epoch 306/400\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 3.5227e-08 - mae: 4.2470e-05 - val_loss: 3.0729e-06 - val_mae: 1.3626e-04\n",
            "Epoch 307/400\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 2.2051e-08 - mae: 2.5872e-05 - val_loss: 2.6419e-06 - val_mae: 1.2802e-04\n",
            "Epoch 308/400\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 3.4898e-08 - mae: 3.3781e-05 - val_loss: 1.6118e-05 - val_mae: 2.8399e-04\n",
            "Epoch 309/400\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 1.0133e-07 - mae: 3.9044e-05 - val_loss: 2.1584e-05 - val_mae: 3.2668e-04\n",
            "Epoch 310/400\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 1.7896e-08 - mae: 2.6503e-05 - val_loss: 9.1370e-05 - val_mae: 6.6653e-04\n",
            "Epoch 311/400\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 1.6052e-08 - mae: 2.7233e-05 - val_loss: 7.3715e-07 - val_mae: 8.4572e-05\n",
            "Epoch 312/400\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 2.6269e-08 - mae: 3.6876e-05 - val_loss: 1.7128e-05 - val_mae: 2.9132e-04\n",
            "Epoch 313/400\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 1.0988e-08 - mae: 2.0633e-05 - val_loss: 3.5309e-06 - val_mae: 1.4131e-04\n",
            "Epoch 314/400\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 3.5378e-08 - mae: 2.8540e-05 - val_loss: 1.0438e-05 - val_mae: 2.2964e-04\n",
            "Epoch 315/400\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 1.9708e-08 - mae: 2.2277e-05 - val_loss: 3.8870e-05 - val_mae: 4.3402e-04\n",
            "Epoch 316/400\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 2.0389e-08 - mae: 2.9729e-05 - val_loss: 4.1560e-05 - val_mae: 4.4836e-04\n",
            "Epoch 317/400\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 1.3762e-07 - mae: 2.7348e-05 - val_loss: 4.0820e-06 - val_mae: 1.4924e-04\n",
            "Epoch 318/400\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 1.0497e-08 - mae: 1.7938e-05 - val_loss: 2.1621e-06 - val_mae: 1.1462e-04\n",
            "Epoch 319/400\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 8.2011e-09 - mae: 1.9445e-05 - val_loss: 2.5584e-07 - val_mae: 7.0092e-05\n",
            "Epoch 320/400\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 3.0752e-08 - mae: 3.1384e-05 - val_loss: 1.3701e-06 - val_mae: 9.6350e-05\n",
            "Epoch 321/400\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 1.8745e-08 - mae: 2.8717e-05 - val_loss: 9.3336e-07 - val_mae: 8.4889e-05\n",
            "Epoch 322/400\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 7.4378e-09 - mae: 1.6906e-05 - val_loss: 9.6147e-07 - val_mae: 8.5288e-05\n",
            "Epoch 323/400\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 1.2027e-08 - mae: 2.7126e-05 - val_loss: 4.2467e-06 - val_mae: 1.5040e-04\n",
            "Epoch 324/400\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 2.5074e-08 - mae: 2.4570e-05 - val_loss: 5.6530e-06 - val_mae: 1.7092e-04\n",
            "Epoch 325/400\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 1.3577e-08 - mae: 1.8274e-05 - val_loss: 5.3483e-07 - val_mae: 7.1962e-05\n",
            "Epoch 326/400\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 3.7099e-08 - mae: 2.8493e-05 - val_loss: 7.9595e-07 - val_mae: 7.9058e-05\n",
            "Epoch 327/400\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 1.0483e-08 - mae: 2.2436e-05 - val_loss: 8.5912e-06 - val_mae: 2.0709e-04\n",
            "Epoch 328/400\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 1.6754e-08 - mae: 1.8777e-05 - val_loss: 1.1049e-06 - val_mae: 8.6972e-05\n",
            "Epoch 329/400\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 2.7738e-08 - mae: 2.4752e-05 - val_loss: 7.4626e-06 - val_mae: 1.9350e-04\n",
            "Epoch 330/400\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 1.8238e-08 - mae: 2.4863e-05 - val_loss: 2.7256e-06 - val_mae: 1.2278e-04\n",
            "Epoch 331/400\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 2.7273e-08 - mae: 2.4894e-05 - val_loss: 2.4998e-06 - val_mae: 1.1822e-04\n",
            "Epoch 332/400\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 2.8720e-08 - mae: 3.1743e-05 - val_loss: 9.0781e-06 - val_mae: 2.1187e-04\n",
            "Epoch 333/400\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 7.3299e-09 - mae: 1.9335e-05 - val_loss: 8.5185e-07 - val_mae: 7.8532e-05\n",
            "Epoch 334/400\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 2.6527e-08 - mae: 3.1933e-05 - val_loss: 2.2002e-06 - val_mae: 1.1140e-04\n",
            "Epoch 335/400\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 1.4617e-08 - mae: 2.3995e-05 - val_loss: 1.3745e-05 - val_mae: 2.5795e-04\n",
            "Epoch 336/400\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 1.1383e-08 - mae: 2.0354e-05 - val_loss: 5.6506e-07 - val_mae: 6.8736e-05\n",
            "Epoch 337/400\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 1.2928e-08 - mae: 1.5412e-05 - val_loss: 1.2725e-06 - val_mae: 8.9085e-05\n",
            "Epoch 338/400\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 1.3156e-08 - mae: 2.2786e-05 - val_loss: 4.5760e-06 - val_mae: 1.5280e-04\n",
            "Epoch 339/400\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 1.7970e-08 - mae: 2.5567e-05 - val_loss: 1.0095e-06 - val_mae: 8.1420e-05\n",
            "Epoch 340/400\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 7.6808e-09 - mae: 1.9937e-05 - val_loss: 1.8498e-05 - val_mae: 2.9715e-04\n",
            "Epoch 341/400\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 6.6135e-08 - mae: 3.0744e-05 - val_loss: 4.1779e-07 - val_mae: 6.2588e-05\n",
            "Epoch 342/400\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 1.4195e-08 - mae: 2.1493e-05 - val_loss: 5.9846e-06 - val_mae: 1.7252e-04\n",
            "Epoch 343/400\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 4.4075e-09 - mae: 1.5152e-05 - val_loss: 2.9022e-06 - val_mae: 1.2373e-04\n",
            "Epoch 344/400\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 1.8868e-08 - mae: 2.1199e-05 - val_loss: 4.8210e-06 - val_mae: 1.5569e-04\n",
            "Epoch 345/400\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 4.5456e-08 - mae: 2.9174e-05 - val_loss: 5.6780e-05 - val_mae: 5.1748e-04\n",
            "Epoch 346/400\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 2.2841e-08 - mae: 3.0016e-05 - val_loss: 1.7839e-05 - val_mae: 2.9132e-04\n",
            "Epoch 347/400\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 1.3934e-08 - mae: 2.3220e-05 - val_loss: 2.2777e-06 - val_mae: 1.1070e-04\n",
            "Epoch 348/400\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 8.2766e-09 - mae: 1.8187e-05 - val_loss: 1.3169e-06 - val_mae: 8.8012e-05\n",
            "Epoch 349/400\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 1.1692e-08 - mae: 1.6367e-05 - val_loss: 1.2624e-06 - val_mae: 8.6409e-05\n",
            "Epoch 350/400\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 9.8813e-09 - mae: 2.3272e-05 - val_loss: 6.6651e-07 - val_mae: 6.8416e-05\n",
            "Epoch 351/400\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 8.1173e-09 - mae: 2.0699e-05 - val_loss: 9.8516e-06 - val_mae: 2.1780e-04\n",
            "Epoch 352/400\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 1.1605e-08 - mae: 1.6429e-05 - val_loss: 2.1200e-05 - val_mae: 3.1640e-04\n",
            "Epoch 353/400\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 6.5887e-09 - mae: 1.4681e-05 - val_loss: 8.3493e-06 - val_mae: 2.0061e-04\n",
            "Epoch 354/400\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 7.6815e-09 - mae: 1.3261e-05 - val_loss: 4.8165e-06 - val_mae: 1.5436e-04\n",
            "Epoch 355/400\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 1.7419e-08 - mae: 2.2996e-05 - val_loss: 2.0333e-05 - val_mae: 3.0959e-04\n",
            "Epoch 356/400\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 3.8994e-09 - mae: 1.4914e-05 - val_loss: 4.1620e-07 - val_mae: 5.8070e-05\n",
            "Epoch 357/400\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 1.2068e-08 - mae: 2.3213e-05 - val_loss: 1.4129e-06 - val_mae: 8.8890e-05\n",
            "Epoch 358/400\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 5.1174e-09 - mae: 1.5800e-05 - val_loss: 3.9274e-07 - val_mae: 5.6565e-05\n",
            "Epoch 359/400\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 9.7222e-09 - mae: 2.0490e-05 - val_loss: 1.4295e-06 - val_mae: 8.9060e-05\n",
            "Epoch 360/400\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 5.6070e-09 - mae: 1.4722e-05 - val_loss: 1.1415e-06 - val_mae: 8.1049e-05\n",
            "Epoch 361/400\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 1.5087e-08 - mae: 2.3875e-05 - val_loss: 4.2193e-06 - val_mae: 1.4420e-04\n",
            "Epoch 362/400\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 7.3360e-09 - mae: 1.5698e-05 - val_loss: 1.7582e-05 - val_mae: 2.8712e-04\n",
            "Epoch 363/400\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 1.0430e-08 - mae: 2.0995e-05 - val_loss: 1.7981e-05 - val_mae: 2.9035e-04\n",
            "Epoch 364/400\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 8.6805e-09 - mae: 1.4774e-05 - val_loss: 1.0993e-05 - val_mae: 2.2800e-04\n",
            "Epoch 365/400\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 2.0721e-09 - mae: 8.0926e-06 - val_loss: 1.1386e-07 - val_mae: 4.5285e-05\n",
            "Epoch 366/400\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 9.5999e-09 - mae: 1.8358e-05 - val_loss: 5.5506e-07 - val_mae: 6.1168e-05\n",
            "Epoch 367/400\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 5.9560e-09 - mae: 1.5133e-05 - val_loss: 3.0832e-07 - val_mae: 5.1263e-05\n",
            "Epoch 368/400\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 7.7096e-09 - mae: 1.7051e-05 - val_loss: 7.0822e-07 - val_mae: 6.6386e-05\n",
            "Epoch 369/400\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 4.5254e-09 - mae: 1.5168e-05 - val_loss: 2.4768e-06 - val_mae: 1.1201e-04\n",
            "Epoch 370/400\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 8.7684e-09 - mae: 1.3289e-05 - val_loss: 1.2012e-06 - val_mae: 8.1476e-05\n",
            "Epoch 371/400\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 1.0538e-09 - mae: 1.0419e-05 - val_loss: 3.2833e-06 - val_mae: 1.2730e-04\n",
            "Epoch 372/400\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 6.7119e-09 - mae: 1.6546e-05 - val_loss: 5.5426e-06 - val_mae: 1.6303e-04\n",
            "Epoch 373/400\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 6.5274e-09 - mae: 1.5874e-05 - val_loss: 2.3870e-07 - val_mae: 4.6957e-05\n",
            "Epoch 374/400\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 2.3938e-09 - mae: 1.2667e-05 - val_loss: 1.1909e-07 - val_mae: 4.2103e-05\n",
            "Epoch 375/400\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 4.0457e-09 - mae: 1.4888e-05 - val_loss: 3.4973e-07 - val_mae: 5.1512e-05\n",
            "Epoch 376/400\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 6.4307e-09 - mae: 1.6700e-05 - val_loss: 4.7393e-06 - val_mae: 1.5100e-04\n",
            "Epoch 377/400\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 5.0720e-09 - mae: 1.5460e-05 - val_loss: 4.5340e-06 - val_mae: 1.4786e-04\n",
            "Epoch 378/400\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 2.8811e-09 - mae: 1.3172e-05 - val_loss: 7.8558e-06 - val_mae: 1.9257e-04\n",
            "Epoch 379/400\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 1.5478e-09 - mae: 9.7631e-06 - val_loss: 1.7999e-07 - val_mae: 4.3022e-05\n",
            "Epoch 380/400\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 4.1462e-09 - mae: 1.2370e-05 - val_loss: 1.7980e-07 - val_mae: 4.2868e-05\n",
            "Epoch 381/400\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 4.8492e-09 - mae: 1.6807e-05 - val_loss: 5.8738e-07 - val_mae: 6.0085e-05\n",
            "Epoch 382/400\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 6.3889e-09 - mae: 1.3277e-05 - val_loss: 8.9445e-07 - val_mae: 7.0748e-05\n",
            "Epoch 383/400\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 9.4549e-09 - mae: 1.5826e-05 - val_loss: 4.5741e-06 - val_mae: 1.4796e-04\n",
            "Epoch 384/400\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 3.6916e-09 - mae: 1.2386e-05 - val_loss: 1.2166e-06 - val_mae: 8.0358e-05\n",
            "Epoch 385/400\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 2.3784e-09 - mae: 1.1577e-05 - val_loss: 1.2003e-07 - val_mae: 3.9067e-05\n",
            "Epoch 386/400\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 4.9336e-09 - mae: 1.7330e-05 - val_loss: 5.7270e-07 - val_mae: 5.8898e-05\n",
            "Epoch 387/400\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 4.5179e-09 - mae: 1.2134e-05 - val_loss: 4.6572e-07 - val_mae: 5.4545e-05\n",
            "Epoch 388/400\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 4.7346e-09 - mae: 1.3109e-05 - val_loss: 8.5548e-07 - val_mae: 6.8976e-05\n",
            "Epoch 389/400\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 6.5680e-09 - mae: 1.3035e-05 - val_loss: 1.4929e-06 - val_mae: 8.7679e-05\n",
            "Epoch 390/400\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 4.1578e-09 - mae: 1.2613e-05 - val_loss: 6.9852e-06 - val_mae: 1.8123e-04\n",
            "Epoch 391/400\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 2.0244e-08 - mae: 1.8556e-05 - val_loss: 2.4503e-07 - val_mae: 4.4001e-05\n",
            "Epoch 392/400\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 6.7198e-09 - mae: 1.2868e-05 - val_loss: 3.3377e-07 - val_mae: 4.8146e-05\n",
            "Epoch 393/400\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 4.6057e-09 - mae: 1.6285e-05 - val_loss: 8.2148e-07 - val_mae: 6.7360e-05\n",
            "Epoch 394/400\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 1.9283e-09 - mae: 1.1099e-05 - val_loss: 1.9827e-07 - val_mae: 4.1171e-05\n",
            "Epoch 395/400\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 3.0858e-09 - mae: 1.3458e-05 - val_loss: 1.2214e-06 - val_mae: 7.9696e-05\n",
            "Epoch 396/400\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 2.4880e-09 - mae: 1.0452e-05 - val_loss: 6.6173e-06 - val_mae: 1.7601e-04\n",
            "Epoch 397/400\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 1.6700e-09 - mae: 8.9709e-06 - val_loss: 4.3046e-07 - val_mae: 5.1973e-05\n",
            "Epoch 398/400\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 2.9112e-09 - mae: 1.1612e-05 - val_loss: 2.5790e-07 - val_mae: 4.3720e-05\n",
            "Epoch 399/400\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 2.6915e-09 - mae: 1.0471e-05 - val_loss: 8.1016e-07 - val_mae: 6.6530e-05\n",
            "Epoch 400/400\n",
            "129/129 [==============================] - 0s 2ms/step - loss: 2.7163e-09 - mae: 1.0491e-05 - val_loss: 1.6604e-06 - val_mae: 9.1207e-05\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "guMjtfa42ahM"
      },
      "source": [
        "### Run with Test Data\n",
        "Put our test data into the model and plot the predictions\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V3Y0CCWJz2EK",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "a99c53d5-05b7-4582-c33b-f054f80a303f"
      },
      "source": [
        "# use the model to predict the test inputs\n",
        "predictions = model.predict(inputs_test)\n",
        "\n",
        "# print the predictions and the expected ouputs\n",
        "print(\"predictions =\\n\", np.round(predictions, decimals=3))\n",
        "print(\"actual =\\n\", outputs_test)\n",
        "\n",
        "# Plot the predictions along with to the test data\n",
        "plt.clf()\n",
        "plt.title('Training data predicted vs actual values')\n",
        "plt.plot(inputs_test, outputs_test, 'b.', label='Actual')\n",
        "plt.plot(inputs_test, predictions, 'r.', label='Predicted')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "predictions =\n",
            " [[0.    0.    1.   ]\n",
            " [0.    1.    0.   ]\n",
            " [0.    0.    1.   ]\n",
            " [1.    0.    0.   ]\n",
            " [0.    1.    0.   ]\n",
            " [1.    0.    0.   ]\n",
            " [0.    1.    0.   ]\n",
            " [1.    0.    0.   ]\n",
            " [0.    0.    1.   ]\n",
            " [1.    0.    0.   ]\n",
            " [0.    0.    1.   ]\n",
            " [0.    0.    1.   ]\n",
            " [1.    0.    0.   ]\n",
            " [0.    1.    0.   ]\n",
            " [0.    0.    1.   ]\n",
            " [0.    0.    1.   ]\n",
            " [1.    0.    0.   ]\n",
            " [0.    1.    0.   ]\n",
            " [0.    1.    0.   ]\n",
            " [0.014 0.    0.986]\n",
            " [0.    0.    1.   ]\n",
            " [1.    0.    0.   ]\n",
            " [1.    0.    0.   ]\n",
            " [0.    1.    0.   ]\n",
            " [0.001 0.    0.999]\n",
            " [1.    0.    0.   ]\n",
            " [0.    0.    1.   ]\n",
            " [0.    0.    1.   ]\n",
            " [0.    0.    1.   ]\n",
            " [0.    1.    0.   ]\n",
            " [1.    0.    0.   ]\n",
            " [0.    0.    1.   ]\n",
            " [1.    0.    0.   ]\n",
            " [0.    0.    1.   ]\n",
            " [1.    0.    0.   ]\n",
            " [1.    0.    0.   ]\n",
            " [0.    1.    0.   ]\n",
            " [1.    0.    0.   ]\n",
            " [1.    0.    0.   ]\n",
            " [0.    1.    0.   ]\n",
            " [0.    1.    0.   ]\n",
            " [1.    0.    0.   ]\n",
            " [0.    1.    0.   ]\n",
            " [1.    0.    0.   ]\n",
            " [1.    0.    0.   ]\n",
            " [1.    0.    0.   ]\n",
            " [1.    0.    0.   ]\n",
            " [0.    0.    1.   ]\n",
            " [1.    0.    0.   ]\n",
            " [0.    1.    0.   ]\n",
            " [1.    0.    0.   ]\n",
            " [0.    1.    0.   ]\n",
            " [0.    0.    1.   ]\n",
            " [1.    0.    0.   ]\n",
            " [0.    0.    1.   ]\n",
            " [0.    1.    0.   ]\n",
            " [0.    1.    0.   ]\n",
            " [0.    1.    0.   ]\n",
            " [0.    0.    1.   ]\n",
            " [1.    0.    0.   ]\n",
            " [0.    0.    1.   ]\n",
            " [0.    1.    0.   ]\n",
            " [1.    0.    0.   ]\n",
            " [0.    1.    0.   ]\n",
            " [1.    0.    0.   ]\n",
            " [1.    0.    0.   ]\n",
            " [0.    1.    0.   ]\n",
            " [1.    0.    0.   ]\n",
            " [1.    0.    0.   ]\n",
            " [1.    0.    0.   ]\n",
            " [0.    0.    1.   ]\n",
            " [0.    0.    1.   ]\n",
            " [1.    0.    0.   ]\n",
            " [0.    0.    1.   ]\n",
            " [0.    1.    0.   ]\n",
            " [0.    0.    1.   ]\n",
            " [0.    0.    1.   ]\n",
            " [1.    0.    0.   ]\n",
            " [0.    1.    0.   ]\n",
            " [0.    0.    1.   ]\n",
            " [0.    1.    0.   ]\n",
            " [1.    0.    0.   ]\n",
            " [1.    0.    0.   ]\n",
            " [1.    0.    0.   ]\n",
            " [1.    0.    0.   ]\n",
            " [1.    0.    0.   ]\n",
            " [0.    0.    1.   ]\n",
            " [0.    1.    0.   ]\n",
            " [1.    0.    0.   ]\n",
            " [0.    1.    0.   ]\n",
            " [0.    1.    0.   ]\n",
            " [0.    1.    0.   ]\n",
            " [1.    0.    0.   ]\n",
            " [0.    0.    1.   ]\n",
            " [1.    0.    0.   ]\n",
            " [1.    0.    0.   ]\n",
            " [1.    0.    0.   ]\n",
            " [0.    1.    0.   ]\n",
            " [0.    1.    0.   ]\n",
            " [0.    1.    0.   ]\n",
            " [1.    0.    0.   ]\n",
            " [0.    1.    0.   ]\n",
            " [1.    0.    0.   ]\n",
            " [0.    1.    0.   ]\n",
            " [1.    0.    0.   ]\n",
            " [0.    0.    1.   ]\n",
            " [0.    0.    1.   ]\n",
            " [0.    1.    0.   ]\n",
            " [0.    1.    0.   ]\n",
            " [1.    0.    0.   ]\n",
            " [0.    1.    0.   ]\n",
            " [1.    0.    0.   ]\n",
            " [0.    0.    1.   ]\n",
            " [0.    1.    0.   ]\n",
            " [1.    0.    0.   ]\n",
            " [1.    0.    0.   ]\n",
            " [1.    0.    0.   ]\n",
            " [0.    0.    1.   ]\n",
            " [1.    0.    0.   ]\n",
            " [0.    0.    1.   ]\n",
            " [0.    1.    0.   ]\n",
            " [0.    0.    1.   ]\n",
            " [0.    1.    0.   ]\n",
            " [1.    0.    0.   ]\n",
            " [0.    1.    0.   ]\n",
            " [0.    1.    0.   ]\n",
            " [0.    0.    1.   ]\n",
            " [1.    0.    0.   ]\n",
            " [1.    0.    0.   ]\n",
            " [0.    1.    0.   ]\n",
            " [1.    0.    0.   ]\n",
            " [0.    0.    1.   ]\n",
            " [0.    0.    1.   ]\n",
            " [0.    0.    1.   ]\n",
            " [0.    0.    1.   ]\n",
            " [0.    0.    1.   ]\n",
            " [1.    0.    0.   ]\n",
            " [0.    0.    1.   ]\n",
            " [1.    0.    0.   ]\n",
            " [0.    1.    0.   ]\n",
            " [1.    0.    0.   ]\n",
            " [0.    0.    1.   ]\n",
            " [0.    1.    0.   ]\n",
            " [0.    0.    1.   ]\n",
            " [0.    0.    1.   ]\n",
            " [1.    0.    0.   ]\n",
            " [1.    0.    0.   ]\n",
            " [1.    0.    0.   ]\n",
            " [0.    0.    1.   ]\n",
            " [0.    1.    0.   ]\n",
            " [1.    0.    0.   ]\n",
            " [1.    0.    0.   ]\n",
            " [1.    0.    0.   ]\n",
            " [1.    0.    0.   ]\n",
            " [1.    0.    0.   ]\n",
            " [1.    0.    0.   ]\n",
            " [1.    0.    0.   ]\n",
            " [0.    0.    1.   ]\n",
            " [1.    0.    0.   ]\n",
            " [1.    0.    0.   ]\n",
            " [0.    0.    1.   ]\n",
            " [1.    0.    0.   ]\n",
            " [0.    1.    0.   ]\n",
            " [1.    0.    0.   ]\n",
            " [0.    0.    1.   ]\n",
            " [0.    0.    1.   ]\n",
            " [0.    0.    1.   ]\n",
            " [0.    1.    0.   ]\n",
            " [0.    1.    0.   ]\n",
            " [0.    1.    0.   ]\n",
            " [0.    1.    0.   ]]\n",
            "actual =\n",
            " [[0. 0. 1.]\n",
            " [0. 1. 0.]\n",
            " [0. 0. 1.]\n",
            " [1. 0. 0.]\n",
            " [0. 1. 0.]\n",
            " [1. 0. 0.]\n",
            " [0. 1. 0.]\n",
            " [1. 0. 0.]\n",
            " [0. 0. 1.]\n",
            " [1. 0. 0.]\n",
            " [0. 0. 1.]\n",
            " [0. 0. 1.]\n",
            " [1. 0. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 0. 1.]\n",
            " [0. 0. 1.]\n",
            " [1. 0. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 0. 1.]\n",
            " [0. 0. 1.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 0. 1.]\n",
            " [1. 0. 0.]\n",
            " [0. 0. 1.]\n",
            " [0. 0. 1.]\n",
            " [0. 0. 1.]\n",
            " [0. 1. 0.]\n",
            " [1. 0. 0.]\n",
            " [0. 0. 1.]\n",
            " [1. 0. 0.]\n",
            " [0. 0. 1.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [0. 1. 0.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [1. 0. 0.]\n",
            " [0. 1. 0.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [0. 0. 1.]\n",
            " [1. 0. 0.]\n",
            " [0. 1. 0.]\n",
            " [1. 0. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 0. 1.]\n",
            " [1. 0. 0.]\n",
            " [0. 0. 1.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 0. 1.]\n",
            " [1. 0. 0.]\n",
            " [0. 0. 1.]\n",
            " [0. 1. 0.]\n",
            " [1. 0. 0.]\n",
            " [0. 1. 0.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [0. 1. 0.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [0. 0. 1.]\n",
            " [0. 0. 1.]\n",
            " [1. 0. 0.]\n",
            " [0. 0. 1.]\n",
            " [0. 1. 0.]\n",
            " [0. 0. 1.]\n",
            " [0. 0. 1.]\n",
            " [1. 0. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 0. 1.]\n",
            " [0. 1. 0.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [0. 0. 1.]\n",
            " [0. 1. 0.]\n",
            " [1. 0. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [1. 0. 0.]\n",
            " [0. 0. 1.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [1. 0. 0.]\n",
            " [0. 1. 0.]\n",
            " [1. 0. 0.]\n",
            " [0. 1. 0.]\n",
            " [1. 0. 0.]\n",
            " [0. 0. 1.]\n",
            " [0. 0. 1.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [1. 0. 0.]\n",
            " [0. 1. 0.]\n",
            " [1. 0. 0.]\n",
            " [0. 0. 1.]\n",
            " [0. 1. 0.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [0. 0. 1.]\n",
            " [1. 0. 0.]\n",
            " [0. 0. 1.]\n",
            " [0. 1. 0.]\n",
            " [0. 0. 1.]\n",
            " [0. 1. 0.]\n",
            " [1. 0. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 0. 1.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [0. 1. 0.]\n",
            " [1. 0. 0.]\n",
            " [0. 0. 1.]\n",
            " [0. 0. 1.]\n",
            " [0. 0. 1.]\n",
            " [0. 0. 1.]\n",
            " [0. 0. 1.]\n",
            " [1. 0. 0.]\n",
            " [0. 0. 1.]\n",
            " [1. 0. 0.]\n",
            " [0. 1. 0.]\n",
            " [1. 0. 0.]\n",
            " [0. 0. 1.]\n",
            " [0. 1. 0.]\n",
            " [0. 0. 1.]\n",
            " [0. 0. 1.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [0. 0. 1.]\n",
            " [0. 1. 0.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [0. 0. 1.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [0. 0. 1.]\n",
            " [1. 0. 0.]\n",
            " [0. 1. 0.]\n",
            " [1. 0. 0.]\n",
            " [0. 0. 1.]\n",
            " [0. 0. 1.]\n",
            " [0. 0. 1.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x72 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j7DO6xxXVCym"
      },
      "source": [
        "# Convert the Trained Model to Tensor Flow Lite\n",
        "\n",
        "The next cell converts the model to TFlite format. The size in bytes of the model is also printed out."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Xn1-Rn9Cp_8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f7a6ee17-8226-4853-9feb-feb834461f53"
      },
      "source": [
        "# Convert the model to the TensorFlow Lite format without quantization\n",
        "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
        "tflite_model = converter.convert()\n",
        "\n",
        "# Save the model to disk\n",
        "open(\"gesture_model.tflite\", \"wb\").write(tflite_model)\n",
        "  \n",
        "import os\n",
        "basic_model_size = os.path.getsize(\"gesture_model.tflite\")\n",
        "print(\"Model is %d bytes\" % basic_model_size)\n",
        "  \n",
        "  "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /tmp/tmpvcgr_b0e/assets\n",
            "Model is 2156 bytes\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ykccQn7SXrUX"
      },
      "source": [
        "## Encode the Model in an Arduino Header File \n",
        "\n",
        "The next cell creates a constant byte array that contains the TFlite model. Import it as a tab with the sketch below."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9J33uwpNtAku",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9f753e32-bf34-4d72-d54f-5869431c9a0d"
      },
      "source": [
        "!echo \"const unsigned char model[] = {\" > /content/model.h\n",
        "!cat gesture_model.tflite | xxd -i      >> /content/model.h\n",
        "!echo \"};\"                              >> /content/model.h\n",
        "\n",
        "import os\n",
        "model_h_size = os.path.getsize(\"model.h\")\n",
        "print(f\"Header file, model.h, is {model_h_size:,} bytes.\")\n",
        "print(\"\\nOpen the side panel (refresh if needed). Double click model.h to download the file.\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Header file, model.h, is 13,330 bytes.\n",
            "\n",
            "Open the side panel (refresh if needed). Double click model.h to download the file.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1eSkHZaLzMId"
      },
      "source": [
        "# Realtime Classification of Sensor Data on Arduino\n",
        "\n",
        "Now it's time to switch back to the tutorial instructions and run our new model on the [Arduino Nano 33 BLE Sense](https://www.arduino.cc/en/Guide/NANO33BLE)"
      ]
    }
  ]
}