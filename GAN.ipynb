{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "GAN.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOmGMkNFV7uFtDOpG+Fu3wA",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/erikk-avans/Machine-Learning/blob/master/GAN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QIN1wqSURwJJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "outputId": "5294ae27-d9b6-4257-f279-e7b032c2a829"
      },
      "source": [
        "!git clone https://github.com/erikk-avans/Machine-Learning.git"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'Machine-Learning'...\n",
            "remote: Enumerating objects: 100, done.\u001b[K\n",
            "remote: Counting objects: 100% (100/100), done.\u001b[K\n",
            "remote: Compressing objects: 100% (100/100), done.\u001b[K\n",
            "remote: Total 100 (delta 43), reused 16 (delta 0), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (100/100), 3.54 MiB | 3.02 MiB/s, done.\n",
            "Resolving deltas: 100% (43/43), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rm5c6xmISKMR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "378ab046-d724-45cf-e909-455421e9bb99"
      },
      "source": [
        "from keras.layers import Conv2D, BatchNormalization, Input, GlobalAveragePooling2D, Dense\n",
        "from keras.models import Model\n",
        "from keras.layers.advanced_activations import LeakyReLU\n",
        "\n",
        "# function for building the discriminator layers\n",
        "def build_discriminator(start_filters, spatial_dim, filter_size):\n",
        "    \n",
        "    # function for building a CNN block for downsampling the image\n",
        "    def add_discriminator_block(x, filters, filter_size):\n",
        "      x = Conv2D(filters, filter_size, padding='same')(x)\n",
        "      x = BatchNormalization()(x)\n",
        "      x = Conv2D(filters, filter_size, padding='same', strides=2)(x)\n",
        "      x = BatchNormalization()(x)\n",
        "      x = LeakyReLU(0.3)(x)\n",
        "      return x\n",
        "    \n",
        "    # input is an image with shape spatial_dim x spatial_dim and 3 channels\n",
        "    inp = Input(shape=(spatial_dim, spatial_dim, 3))\n",
        "\n",
        "    # design the discrimitor to downsample the image 4x\n",
        "    x = add_discriminator_block(inp, start_filters, filter_size)\n",
        "    x = add_discriminator_block(x, start_filters * 2, filter_size)\n",
        "    x = add_discriminator_block(x, start_filters * 4, filter_size)\n",
        "    x = add_discriminator_block(x, start_filters * 8, filter_size)\n",
        "    \n",
        "    # average and return a binary output\n",
        "    x = GlobalAveragePooling2D()(x)\n",
        "    x = Dense(1, activation='sigmoid')(x)\n",
        "    \n",
        "    return Model(inputs=inp, outputs=x)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V6IR6TJ8ScyJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.layers import Deconvolution2D, Reshape\n",
        "\n",
        "def build_generator(start_filters, filter_size, latent_dim):\n",
        "  \n",
        "  # function for building a CNN block for upsampling the image\n",
        "  def add_generator_block(x, filters, filter_size):\n",
        "      x = Deconvolution2D(filters, filter_size, strides=2, padding='same')(x)\n",
        "      x = BatchNormalization()(x)\n",
        "      x = LeakyReLU(0.3)(x)\n",
        "      return x\n",
        "\n",
        "  # input is a noise vector \n",
        "  inp = Input(shape=(latent_dim,))\n",
        "\n",
        "  # projection of the noise vector into a tensor with \n",
        "  # same shape as last conv layer in discriminator\n",
        "  x = Dense(4 * 4 * (start_filters * 8), input_dim=latent_dim)(inp)\n",
        "  x = BatchNormalization()(x)\n",
        "  x = Reshape(target_shape=(4, 4, start_filters * 8))(x)\n",
        "\n",
        "  # design the generator to upsample the image 4x\n",
        "  x = add_generator_block(x, start_filters * 4, filter_size)\n",
        "  x = add_generator_block(x, start_filters * 2, filter_size)\n",
        "  x = add_generator_block(x, start_filters, filter_size)\n",
        "  x = add_generator_block(x, start_filters, filter_size)    \n",
        "\n",
        "  # turn the output into a 3D tensor, an image with 3 channels \n",
        "  x = Conv2D(3, kernel_size=5, padding='same', activation='tanh')(x)\n",
        "  \n",
        "  return Model(inputs=inp, outputs=x)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ODRh6p0naVVy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "outputId": "9bed2695-f5e9-45a1-c4cf-0938bde16ac4"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ps9ARx9naewv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "os.chdir('/content/drive/My Drive/AI/Deep Learning/Lab/GAN/')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UUSjV-vHSlMV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "e97a9b42-e4bb-4adb-fe35-8bd577a15a87"
      },
      "source": [
        "import pandas as pd\n",
        "#import os\n",
        "from keras.optimizers import Adam\n",
        "\n",
        "#I added this one manually as it was missing in the example\n",
        "from keras.models import Sequential, Model\n",
        "\n",
        "# load celebrity images attributes\n",
        "df_celeb = pd.read_csv('/content/drive/My Drive/AI/Deep Learning/Lab/GAN/list_attr_celeba.csv')\n",
        "TOTAL_SAMPLES = df_celeb.shape[0]\n",
        "\n",
        "# we will downscale the images\n",
        "SPATIAL_DIM = 64 \n",
        "# size of noise vector\n",
        "LATENT_DIM_GAN = 100 \n",
        "# filter size in conv layer\n",
        "FILTER_SIZE = 5\n",
        "# number of filters in conv layer\n",
        "NET_CAPACITY = 16\n",
        "# batch size\n",
        "BATCH_SIZE_GAN = 32\n",
        "# interval for displaying generated images\n",
        "PROGRESS_INTERVAL = 80 \n",
        "# directory for storing generated images\n",
        "ROOT_DIR = 'visualization'\n",
        "if not os.path.isdir(ROOT_DIR):\n",
        "    os.mkdir(ROOT_DIR)\n",
        "    \n",
        "\n",
        "\n",
        "def construct_models(verbose=False):\n",
        "    ### discriminator\n",
        "    discriminator = build_discriminator(NET_CAPACITY, SPATIAL_DIM, FILTER_SIZE)\n",
        "    # compile discriminator\n",
        "    discriminator.compile(loss='binary_crossentropy', optimizer=Adam(lr=0.0002), metrics=['mae'])\n",
        "\n",
        "    ### generator\n",
        "    # do not compile generator\n",
        "    generator = build_generator(NET_CAPACITY, FILTER_SIZE, LATENT_DIM_GAN)\n",
        "\n",
        "    ### DCGAN \n",
        "    gan = Sequential()\n",
        "    gan.add(generator)\n",
        "    gan.add(discriminator)\n",
        "    discriminator.trainable = False \n",
        "    gan.compile(loss='binary_crossentropy', optimizer=Adam(lr=0.0002), metrics=['mae'])\n",
        "\n",
        "    if verbose: \n",
        "        generator.summary()\n",
        "        discriminator.summary()\n",
        "        gan.summary()\n",
        "        \n",
        "    return generator, discriminator, gan\n",
        "  \n",
        "generator_celeb, discriminator_celeb, gan_celeb = construct_models(verbose=True)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_10\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_10 (InputLayer)        (None, 100)               0         \n",
            "_________________________________________________________________\n",
            "dense_10 (Dense)             (None, 2048)              206848    \n",
            "_________________________________________________________________\n",
            "batch_normalization_61 (Batc (None, 2048)              8192      \n",
            "_________________________________________________________________\n",
            "reshape_5 (Reshape)          (None, 4, 4, 128)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_transpose_17 (Conv2DT (None, 8, 8, 64)          204864    \n",
            "_________________________________________________________________\n",
            "batch_normalization_62 (Batc (None, 8, 8, 64)          256       \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_37 (LeakyReLU)   (None, 8, 8, 64)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_transpose_18 (Conv2DT (None, 16, 16, 32)        51232     \n",
            "_________________________________________________________________\n",
            "batch_normalization_63 (Batc (None, 16, 16, 32)        128       \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_38 (LeakyReLU)   (None, 16, 16, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_transpose_19 (Conv2DT (None, 32, 32, 16)        12816     \n",
            "_________________________________________________________________\n",
            "batch_normalization_64 (Batc (None, 32, 32, 16)        64        \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_39 (LeakyReLU)   (None, 32, 32, 16)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_transpose_20 (Conv2DT (None, 64, 64, 16)        6416      \n",
            "_________________________________________________________________\n",
            "batch_normalization_65 (Batc (None, 64, 64, 16)        64        \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_40 (LeakyReLU)   (None, 64, 64, 16)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_45 (Conv2D)           (None, 64, 64, 3)         1203      \n",
            "=================================================================\n",
            "Total params: 492,083\n",
            "Trainable params: 487,731\n",
            "Non-trainable params: 4,352\n",
            "_________________________________________________________________\n",
            "Model: \"model_9\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_9 (InputLayer)         (None, 64, 64, 3)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_37 (Conv2D)           (None, 64, 64, 16)        1216      \n",
            "_________________________________________________________________\n",
            "batch_normalization_53 (Batc (None, 64, 64, 16)        64        \n",
            "_________________________________________________________________\n",
            "conv2d_38 (Conv2D)           (None, 32, 32, 16)        6416      \n",
            "_________________________________________________________________\n",
            "batch_normalization_54 (Batc (None, 32, 32, 16)        64        \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_33 (LeakyReLU)   (None, 32, 32, 16)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_39 (Conv2D)           (None, 32, 32, 32)        12832     \n",
            "_________________________________________________________________\n",
            "batch_normalization_55 (Batc (None, 32, 32, 32)        128       \n",
            "_________________________________________________________________\n",
            "conv2d_40 (Conv2D)           (None, 16, 16, 32)        25632     \n",
            "_________________________________________________________________\n",
            "batch_normalization_56 (Batc (None, 16, 16, 32)        128       \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_34 (LeakyReLU)   (None, 16, 16, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_41 (Conv2D)           (None, 16, 16, 64)        51264     \n",
            "_________________________________________________________________\n",
            "batch_normalization_57 (Batc (None, 16, 16, 64)        256       \n",
            "_________________________________________________________________\n",
            "conv2d_42 (Conv2D)           (None, 8, 8, 64)          102464    \n",
            "_________________________________________________________________\n",
            "batch_normalization_58 (Batc (None, 8, 8, 64)          256       \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_35 (LeakyReLU)   (None, 8, 8, 64)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_43 (Conv2D)           (None, 8, 8, 128)         204928    \n",
            "_________________________________________________________________\n",
            "batch_normalization_59 (Batc (None, 8, 8, 128)         512       \n",
            "_________________________________________________________________\n",
            "conv2d_44 (Conv2D)           (None, 4, 4, 128)         409728    \n",
            "_________________________________________________________________\n",
            "batch_normalization_60 (Batc (None, 4, 4, 128)         512       \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_36 (LeakyReLU)   (None, 4, 4, 128)         0         \n",
            "_________________________________________________________________\n",
            "global_average_pooling2d_5 ( (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_9 (Dense)              (None, 1)                 129       \n",
            "=================================================================\n",
            "Total params: 1,632,098\n",
            "Trainable params: 815,569\n",
            "Non-trainable params: 816,529\n",
            "_________________________________________________________________\n",
            "Model: \"sequential_4\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "model_10 (Model)             (None, 64, 64, 3)         492083    \n",
            "_________________________________________________________________\n",
            "model_9 (Model)              (None, 1)                 816529    \n",
            "=================================================================\n",
            "Total params: 1,308,612\n",
            "Trainable params: 487,731\n",
            "Non-trainable params: 820,881\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/keras/engine/training.py:297: UserWarning: Discrepancy between trainable weights and collected trainable weights, did you set `model.trainable` without calling `model.compile` after ?\n",
            "  'Discrepancy between trainable weights and collected trainable'\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QXPtp1abb3Ex",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        },
        "outputId": "a51b99f1-26aa-481e-9523-44e8b8b355cd"
      },
      "source": [
        "df_celeb.head()"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>image_id</th>\n",
              "      <th>5_o_Clock_Shadow</th>\n",
              "      <th>Arched_Eyebrows</th>\n",
              "      <th>Attractive</th>\n",
              "      <th>Bags_Under_Eyes</th>\n",
              "      <th>Bald</th>\n",
              "      <th>Bangs</th>\n",
              "      <th>Big_Lips</th>\n",
              "      <th>Big_Nose</th>\n",
              "      <th>Black_Hair</th>\n",
              "      <th>Blond_Hair</th>\n",
              "      <th>Blurry</th>\n",
              "      <th>Brown_Hair</th>\n",
              "      <th>Bushy_Eyebrows</th>\n",
              "      <th>Chubby</th>\n",
              "      <th>Double_Chin</th>\n",
              "      <th>Eyeglasses</th>\n",
              "      <th>Goatee</th>\n",
              "      <th>Gray_Hair</th>\n",
              "      <th>Heavy_Makeup</th>\n",
              "      <th>High_Cheekbones</th>\n",
              "      <th>Male</th>\n",
              "      <th>Mouth_Slightly_Open</th>\n",
              "      <th>Mustache</th>\n",
              "      <th>Narrow_Eyes</th>\n",
              "      <th>No_Beard</th>\n",
              "      <th>Oval_Face</th>\n",
              "      <th>Pale_Skin</th>\n",
              "      <th>Pointy_Nose</th>\n",
              "      <th>Receding_Hairline</th>\n",
              "      <th>Rosy_Cheeks</th>\n",
              "      <th>Sideburns</th>\n",
              "      <th>Smiling</th>\n",
              "      <th>Straight_Hair</th>\n",
              "      <th>Wavy_Hair</th>\n",
              "      <th>Wearing_Earrings</th>\n",
              "      <th>Wearing_Hat</th>\n",
              "      <th>Wearing_Lipstick</th>\n",
              "      <th>Wearing_Necklace</th>\n",
              "      <th>Wearing_Necktie</th>\n",
              "      <th>Young</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>000001.jpg</td>\n",
              "      <td>-1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>-1</td>\n",
              "      <td>1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>-1</td>\n",
              "      <td>1</td>\n",
              "      <td>-1</td>\n",
              "      <td>1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>000002.jpg</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>1</td>\n",
              "      <td>-1</td>\n",
              "      <td>1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>000003.jpg</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>000004.jpg</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>1</td>\n",
              "      <td>-1</td>\n",
              "      <td>1</td>\n",
              "      <td>-1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>-1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>000005.jpg</td>\n",
              "      <td>-1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     image_id  5_o_Clock_Shadow  ...  Wearing_Necktie  Young\n",
              "0  000001.jpg                -1  ...               -1      1\n",
              "1  000002.jpg                -1  ...               -1      1\n",
              "2  000003.jpg                -1  ...               -1      1\n",
              "3  000004.jpg                -1  ...               -1      1\n",
              "4  000005.jpg                -1  ...               -1      1\n",
              "\n",
              "[5 rows x 41 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "peLIxOhdb3iZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P419AQJ5WoWJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 341
        },
        "outputId": "27690090-84fa-41cc-e450-45aa3aad2e99"
      },
      "source": [
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "%matplotlib inline\n",
        "from IPython.display import clear_output\n",
        " \n",
        "# number of discriminator updates per alternating training iteration\n",
        "DISC_UPDATES = 1  \n",
        "# number of generator updates per alternating training iteration\n",
        "GEN_UPDATES = 1 \n",
        "\n",
        "# function for training a GAN\n",
        "def run_training(generator, discriminator, gan, df=df_celeb, start_it=0, num_epochs=1000, \n",
        "                 get_real_images=get_real_celebrity):\n",
        "\n",
        "  # helper function for selecting 'size' real images\n",
        "  # and downscaling them to lower dimension SPATIAL_DIM\n",
        "  def get_real_celebrity(df, size, total):\n",
        "      cur_files = df.sample(frac=1).iloc[0:size]\n",
        "      X = np.empty(shape=(size, SPATIAL_DIM, SPATIAL_DIM, 3))\n",
        "      for i in range(0, size):\n",
        "          file = cur_files.iloc[i]\n",
        "          img_uri = 'img_align_celeba/' + file.image_id\n",
        "          img = cv2.imread(img_uri)\n",
        "          img = cv2.resize(img, (SPATIAL_DIM, SPATIAL_DIM))\n",
        "          img = np.flip(img, axis=2)\n",
        "          img = img.astype(np.float32) / 127.5 - 1.0\n",
        "          X[i] = img\n",
        "      return X\n",
        "  \n",
        "  # list for storing loss\n",
        "  avg_loss_discriminator = []\n",
        "  avg_loss_generator = []\n",
        "  total_it = start_it\n",
        "\n",
        "  # main training loop\n",
        "  for epoch in range(num_epochs):\n",
        "\n",
        "      # alternating training loop\n",
        "      loss_discriminator = []\n",
        "      loss_generator = []\n",
        "      for it in range(200): \n",
        "\n",
        "          #### Discriminator training loop ####\n",
        "          for i in range(DISC_UPDATES): \n",
        "              # select a random set of real images\n",
        "              imgs_real = get_real_images(df, BATCH_SIZE_GAN, TOTAL_SAMPLES)\n",
        "              # generate a set of random noise vectors\n",
        "              noise = np.random.randn(BATCH_SIZE_GAN, LATENT_DIM_GAN)\n",
        "              # generate a set of fake images using the generator\n",
        "              imgs_fake = generator.predict(noise)\n",
        "              # train the discriminator on real images with label 1\n",
        "              d_loss_real = discriminator.train_on_batch(imgs_real, np.ones([BATCH_SIZE_GAN]))[1]\n",
        "              # train the discriminator on fake images with label 0\n",
        "              d_loss_fake = discriminator.train_on_batch(imgs_fake, np.zeros([BATCH_SIZE_GAN]))[1]\n",
        "\n",
        "          # display some fake images for visual control of convergence\n",
        "          if total_it % PROGRESS_INTERVAL == 0:\n",
        "              plt.figure(figsize=(5,2))\n",
        "              num_vis = min(BATCH_SIZE_GAN, 5)\n",
        "              imgs_real = get_real_images(df, num_vis, TOTAL_SAMPLES)\n",
        "              noise = np.random.randn(num_vis, LATENT_DIM_GAN)\n",
        "              imgs_fake = generator.predict(noise)\n",
        "              for obj_plot in [imgs_fake, imgs_real]:\n",
        "                  plt.figure(figsize=(num_vis * 3, 3))\n",
        "                  for b in range(num_vis):\n",
        "                      disc_score = float(discriminator.predict(np.expand_dims(obj_plot[b], axis=0))[0])\n",
        "                      plt.subplot(1, num_vis, b + 1)\n",
        "                      plt.title(str(round(disc_score, 3)))\n",
        "                      plt.imshow(obj_plot[b] * 0.5 + 0.5) \n",
        "                  if obj_plot is imgs_fake:\n",
        "                      plt.savefig(os.path.join(ROOT_DIR, str(total_it).zfill(10) + '.jpg'), format='jpg', bbox_inches='tight')\n",
        "                  plt.show()  \n",
        "\n",
        "          #### Generator training loop ####\n",
        "          loss = 0\n",
        "          y = np.ones([BATCH_SIZE_GAN, 1]) \n",
        "          for j in range(GEN_UPDATES):\n",
        "              # generate a set of random noise vectors\n",
        "              noise = np.random.randn(BATCH_SIZE_GAN, LATENT_DIM_GAN)\n",
        "              # train the generator on fake images with label 1\n",
        "              loss += gan.train_on_batch(noise, y)[1]\n",
        "\n",
        "          # store loss\n",
        "          loss_discriminator.append((d_loss_real + d_loss_fake) / 2.)        \n",
        "          loss_generator.append(loss / GEN_UPDATES)\n",
        "          total_it += 1\n",
        "\n",
        "      # visualize loss\n",
        "      clear_output(True)\n",
        "      print('Epoch', epoch)\n",
        "      avg_loss_discriminator.append(np.mean(loss_discriminator))\n",
        "      avg_loss_generator.append(np.mean(loss_generator))\n",
        "      plt.plot(range(len(avg_loss_discriminator)), avg_loss_discriminator)\n",
        "      plt.plot(range(len(avg_loss_generator)), avg_loss_generator)\n",
        "      plt.legend(['discriminator loss', 'generator loss'])\n",
        "      plt.show()\n",
        "\n",
        "  return generator, discriminator, gan\n",
        "\n",
        "generator_celeb, discriminator_celeb, gan_celeb = run_training(generator_celeb, \n",
        "                                                               discriminator_celeb, \n",
        "                                                               gan_celeb, \n",
        "                                                               num_epochs=500, \n",
        "                                                               df=df_celeb)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "error",
          "ename": "error",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31merror\u001b[0m                                     Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-24-953616d9ffda>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    103\u001b[0m                                                                \u001b[0mgan_celeb\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m                                                                \u001b[0mnum_epochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m500\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 105\u001b[0;31m                                                                df=df_celeb)\n\u001b[0m",
            "\u001b[0;32m<ipython-input-24-953616d9ffda>\u001b[0m in \u001b[0;36mrun_training\u001b[0;34m(generator, discriminator, gan, df, start_it, num_epochs, get_real_images)\u001b[0m\n\u001b[1;32m     45\u001b[0m           \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDISC_UPDATES\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m               \u001b[0;31m# select a random set of real images\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m               \u001b[0mimgs_real\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_real_images\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBATCH_SIZE_GAN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTOTAL_SAMPLES\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     48\u001b[0m               \u001b[0;31m# generate a set of random noise vectors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m               \u001b[0mnoise\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBATCH_SIZE_GAN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mLATENT_DIM_GAN\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-16-e3e8344aede5>\u001b[0m in \u001b[0;36mget_real_celebrity\u001b[0;34m(df, size, total)\u001b[0m\n\u001b[1;32m      6\u001b[0m          \u001b[0mimg_uri\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'img_align_celeba/'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimage_id\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m          \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_uri\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m          \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mSPATIAL_DIM\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSPATIAL_DIM\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m          \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m          \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;36m127.5\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1.0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31merror\u001b[0m: OpenCV(4.1.2) /io/opencv/modules/imgproc/src/resize.cpp:3720: error: (-215:Assertion failed) !ssize.empty() in function 'resize'\n"
          ]
        }
      ]
    }
  ]
}